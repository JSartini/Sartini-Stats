{
  "hash": "08abecf3c121151678cfe84427dd2306",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"MSFAST: Bayesian Multivariate, Sparse FPCA Vignette\"\ndate: 09/03/2025\nauthor: Joseph Sartini\neditor: source\nbibliography: MSFAST_refs.bib\nlink-citations: true\noutput: html_document\n---\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# General helper functions\nsource(\"MSFAST_support/Libs.R\")\nsource(\"MSFAST_support/Bases.R\")\nsource(\"MSFAST_support/PostProcess.R\")\nsource(\"MSFAST_support/Convergence.R\")\n\n# Supporting functions for MSFAST\nsource(\"MSFAST_support/MSFAST_Help.R\")\nsource(\"MSFAST_support/Resample_Scores.R\")\n```\n:::\n\n\n## Read in the CONTENT Child Growth Data\n\nFor this vignette, we analyze a subset ($N = 197$) of child growth data from the CONTENT study as included in the [\"refund\"](https://cran.r-project.org/web/packages/refund/index.html) package. As part of CONTENT, multiple growth measures were taken at the same time for each participant and sparsely across individuals.\n\nCONTENT was conducted between May 2007 and February 2011 in Las Pampas de San Juan Miraflores and Nuevo Paraíso, two peri-urban shanty towns located on the southern edge of Lima City in Peru. The shanty towns had approximately $40{,}000$ residents with $25$% of the population under the age of $5$ [@checkley_effects_1998; @checkley_effects_2003].\n\nA simple census was conducted to identify pregnant women and children less than $3$ months old. Eligible newborns and pregnant women were randomly selected and invited to participate in the study (at most one newborn per household). The longitudinal cohort study aimed to assess whether Helicobacter pylori (H. pylori) infection adversely affects the growth in children less than $2$ years of age [@jaganath_first_2014; @crainiceanu2024book].\n\nThe study aimed to collect measures weekly until the child was $3$ months old, biweekly between $3$ and $11$ months, and once monthly afterwards. Some visits were missed or canceled, contributing to the sparse data structure.\n\nWe read in the data using standard Tidyverse syntax, focusing on the length and weight z-scores relative to the age- and sex-specific World Health Organization standards.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(content)\n\ncontent = content %>%\n  select(id, ma1fe0, agedays, zlen, zwei)\n```\n:::\n\n\n## Visualization of the Sparse Structure\n\nWe now visualize the observation times by gender for the entire dataset and the observed data for four participants (two randomly chosen and two chosen for holdout to illustrate dynamic prediction). These visualizations borrow strongly from the section in [\"Functional Data Analysis with R\"](https://functionaldataanalysis.org) on sparsely observed functional data, which includes discussion of the CONTENT dataset. The first visualization aims to illustrate the general structure of the sparsity in observations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(37578) # Essential for reproducibility\nfor_prediction = c(73, 112) # Participants for dynamic prediction\n\nvis_ppts = c(sample(unique(content %>% filter(ma1fe0 == 0) %>% pull(id)), 1), \n             for_prediction[1], \n             sample(unique(content %>% filter(ma1fe0 == 1) %>% pull(id)), 1), \n             for_prediction[2])\n\ncontent %>%\n  select(id, ma1fe0, agedays) %>%\n  mutate(Gender = case_when(ma1fe0 == 1 ~ \"Male\", \n                            TRUE ~ \"Female\")) %>%\n  group_by(Gender, id) %>%\n  nest(data = agedays) %>%\n  ungroup() %>%\n  group_by(Gender) %>%\n  mutate(pptid = row_number()) %>%\n  ungroup() %>%\n  unnest(data) %>%\n  mutate(coloring = case_when(id %in% vis_ppts ~ \"Observed\", \n                              TRUE ~ \"Excluded\")) %>%\n  ggplot(aes(x = agedays, y = pptid)) + \n  geom_point(aes(color = coloring), size = 1) + \n  theme_bw() + \n  facet_wrap(.~Gender) + \n  scale_color_manual(values = c(\"Observed\" = \"darkorange\", \n                                \"Excluded\" = \"steelblue\")) + \n  labs(x = \"Age (Days)\", y = \"Participant\", title = \"\") +\n  theme(axis.text.y = element_blank(), \n        axis.ticks.y = element_blank(), \n        legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](MSFAST_Vignette_files/figure-html/data_vis_1-1.png){width=1152}\n:::\n:::\n\n\nFocusing on just four participants, two of each gender highlighted in the above observations plot, we can better visualize the actual bivariate patterns within the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlabs = c(paste0(c(\"Female\", \"Male\"), \" Ppt. 1\"), \n         paste0(c(\"Female\", \"Male\"), \" Ppt. 2\"))\ncontent %>%\n  filter(id %in% vis_ppts) %>%\n  mutate(new_id = case_when(id == vis_ppts[1] ~ labs[1], \n                            id == vis_ppts[2] ~ labs[3], \n                            id == vis_ppts[3] ~ labs[2], \n                            TRUE ~ labs[4]), \n         new_id = factor(new_id, levels = labs)) %>%\n  select(new_id, id, agedays, zlen, zwei) %>%\n  pivot_longer(-c(new_id, id, agedays), names_to = \"Measure\", values_to = \"Y\") %>%\n  mutate(Measure = case_when(Measure == \"zlen\" ~ \"Length\", \n                             TRUE ~ \"Weight\")) %>%\n  ggplot(aes(x = agedays, y = Y, group = Measure, color = Measure)) + \n  geom_point() + \n  facet_wrap(.~new_id, ncol = 2) + \n  theme_bw() + \n  labs(x = \"Age (Days)\", y = \"Z-Score\", title = \"\") + \n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](MSFAST_Vignette_files/figure-html/data_vis_2-1.png){width=1152}\n:::\n:::\n\n\n## Fitting MSFAST\n\nWe first remove two participants from the dataset that will be used to fit the model. We will illustrate dynamic prediction using the data from these participants later.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontent_fit = content %>%\n  filter(!(id %in% for_prediction)) %>%\n  select(-c(ma1fe0))\n\ncontent_predict = content %>%\n  filter(id %in% for_prediction) %>%\n  select(-c(ma1fe0)) %>%\n  rename(Arg = agedays)\n```\n:::\n\n\nAt this point, we form the input data list required by MSFAST, described in the \"Bayesian implementation in STAN\" section of the manuscript.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Pivot to long and adjust names\nfit_df = content_fit %>%\n  pivot_longer(-c(id, agedays),\n               names_to = \"Covar\",\n               values_to = \"Y\") %>%\n  mutate(Var = case_when(Covar == \"zlen\" ~ 1, # Replace names with indices\n                         TRUE ~ 2)) %>%\n  select(-c(Covar)) %>%\n  reset_id() %>% # Reset participant ids to sequential integers\n  rename(Subj = id, Arg = agedays)\n\n# Find observation time indices S and append\nS_df = data.frame(Arg = sort(unique(fit_df$Arg)))\nS_df$S = 1:nrow(S_df)\nfit_df = inner_join(fit_df, S_df, by = \"Arg\")\ncontent_predict = inner_join(content_predict, S_df, by = \"Arg\")\n\n# Translate domain to (0, 1)\ndomain = S_df$Arg\nscaled_domain = (domain - min(domain)) / (max(domain) - min(domain))\n\nN = n_distinct(fit_df$Subj)   # Number of participants\nQ = 20                        # Spline basis dimension\nK = 4                         # Number of principal components\nP = n_distinct(fit_df$Var)    # Number of unique covariates (2 here)\n\n# Function to coalesce inputs (basis is orthogonalized B-splines by default)\ndata_list = MSFAST_datalist(fit_df, N = N, K = K, Q = Q, scaled_domain, \n                            scale = T)\n```\n:::\n\n\nWe can finally fit the model using RSTAN as follows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_joint = stan(\"MSFAST_support/MSFAST.stan\", \n                 data = data_list, \n                 chains = 4, \n                 cores = 4, \n                 warmup = 2000, \n                 iter = 3000, \n                 control = list(max_treedepth = 12))\n```\n:::\n\n\nNote that the above block does not leverage parallelization over covariates through multithreading. To leverage this computational speed-up (after ensuring sufficient available resources), one can use \"Sys.setenv(STAN_NUM_THREADS=X)\" for $\\text{X} > 1$ and the parallelized STAN implementation.\n\n## Evaluating Fit and Aligning Results\n\nWe first fit mFACEs, extracting the estimates provided by this method to be used as our fixed point $\\widetilde{\\boldsymbol{\\Phi}}$ for the Procrustes-based alignment of posterior FPC samples described in the manuscript.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Data in list format\nface_data = list(content %>% \n                   filter(!(id %in% for_prediction)) %>%\n                   select(agedays, id, zlen) %>%\n                   rename(argvals = agedays, \n                          subj = id, y = zlen), \n                 content %>%\n                   filter(!(id %in% for_prediction)) %>%\n                   select(agedays, id, zwei) %>%\n                   rename(argvals = agedays, \n                          subj = id, y = zwei))\n\n# Call to function\nface_fit = mface.sparse(face_data, argvals.new = domain, knots = Q-3,\n                        knots.option = \"quantile\", pve = 0.999)\n\n# Extract first K FPC estimates as fixed point matrix\nphi_tilde = face_fit$eigenfunctions[,1:K] \n```\n:::\n\n\nWe next check the Gelman-Rubin statistics for all relevant model components (after alignment). This is done automatically using the \"RHat_FAST()\" function as follows. This function calculates the median and max RHat observed for each FPC/covariate grouping within parameter families. The results below indicate that all parameters have converged according to the heuristic RHat < 1.05 threshold. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nrhats = RHat_FAST(fit_joint,   # RSTAN object \n                  data_list,   # List of constants\n                  data_list$B, # Orthogonal spline basis matrix\n                  phi_tilde)   # Fixed point for rotational alignment\n\n# Scores, grouped by FPC\nrhats$Score\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  FPC_Num Med_RHat Max_RHat\n  <chr>      <dbl>    <dbl>\n1 FPC 1       1.02     1.04\n2 FPC 2       1.00     1.01\n3 FPC 3       1.00     1.01\n4 FPC 4       1.00     1.02\n```\n\n\n:::\n\n```{.r .cell-code}\n# FPCs, grouped by FPC/functional component\nrhats$Func\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 3\n  Function Med_RHat Max_RHat\n  <chr>       <dbl>    <dbl>\n1 FPC 1        1.00     1.01\n2 FPC 2        1.00     1.00\n3 FPC 3        1.00     1.02\n4 FPC 4        1.01     1.03\n5 Mu           1.00     1.00\n```\n\n\n:::\n\n```{.r .cell-code}\n# Fixed effect smoothing parameters, grouped by covariate\nrhats$Mu_Smoothing\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Function     RHat\n1      Mu1 1.001001\n2      Mu2 1.001592\n```\n\n\n:::\n\n```{.r .cell-code}\n# FPC smoothing parameters, grouped by FPC and covariate\nrhats$FPC_Smoothing\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 × 3\n  Var   FPC    RHat\n  <chr> <chr> <dbl>\n1 Var 1 FPC 1  1.02\n2 Var 1 FPC 2  1.01\n3 Var 1 FPC 3  1.00\n4 Var 1 FPC 4  1.00\n5 Var 2 FPC 1  1.00\n6 Var 2 FPC 2  1.01\n7 Var 2 FPC 3  1.01\n8 Var 2 FPC 4  1.00\n```\n\n\n:::\n\n```{.r .cell-code}\n# Variance components, no grouping\nrhats$Variances\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Element     RHat\n1 Lambda_1 1.000116\n2 Lambda_2 1.001444\n3 Lambda_3 1.007298\n4 Lambda_4 1.027927\n5   Sigma2 1.000165\n```\n\n\n:::\n:::\n\n\nWe can extract and align the posterior samples, leveraging the Procrustes-based procedure described in the manuscript, using the provided suite of post-processing functions as follows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Can adjust the observation points at which inference is performed\nbasis_mat = FAST_B(\"B\", Q, scaled_domain)\n\n# Extract FPCs, corresponding weights, fixed effect weights, and scores\nobjects = FAST_extract(fit_joint, basis_mat, data_list)\n\n# Align samples using Procrustes-based procedure\nalign = procrust_WEI(objects$Weights, basis_mat, P, phi_tilde, objects$Score)\n\n# Extract FPC estimates and credible intervals\nEF_ests = FPC_Est_WEI(align$Weight, basis_mat, P, domain, phi_tilde)\nEF_bounds = FPC_CI(align$EF, domain, P)\n```\n:::\n\n\nWe next evaluate the proportion of global variability explained to ensure the number of FPCs $K$ was chosen appropriately. The final values are above 95% for all samples, seeming to indicate that $K = 4$ is sufficient for this data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# True data in sparse matrix form\ndata_matrix = fit_df %>%\n  pivot_wider(names_from = Subj, values_from = Y) %>%\n  arrange(Var, Arg) %>%\n  select(-c(Var, Arg, S)) %>%\n  as.matrix() %>%\n  t()\nmask = is.na(data_matrix)\ndata_var = var(data_matrix[!mask])\n\n# Modeled smooths in sparse matrix of dim. samples x ppts x obs\nsamples_matrix = Smooth_Raw(objects$Mu, align$EF, align$Score, data_list)\nn_samp = dim(samples_matrix)[1]\nvar_expl = rep(0, n_samp)\nfor (j in 1:n_samp) {\n  model_matrix = samples_matrix[j, , ]\n  resids = data_matrix - model_matrix\n  var_expl[j] = 1 - var(resids[!mask]) / data_var # 1 - RSS/TSS across covariates\n}\n\n# Summarize global variance explained over posterior samples\nsummary(var_expl)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.9501  0.9509  0.9511  0.9511  0.9512  0.9520 \n```\n\n\n:::\n:::\n\n\n## Visualizing Multivariate FPCs\n\nWe now visualize the multivariate FPCs according to MSFAST. All estimates are accompanied by the associated equal-tailed 95% credible intervals. For a point of reference, we also include the FPC estimates from mFACEs, though these estimates do not include any uncertainty quantification.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Format MSFAST estimates\n{\n  MSFAST_FPC = left_join(EF_bounds, EF_ests %>% rename(Func = FPC_Val)) %>%\n    mutate(FuncName = paste0(\"phi[\", substring(FPC_Num, 5), \"](t)\")) %>%\n    mutate(Method = \"MSFAST\", \n           Method = factor(Method, levels = c(\"MSFAST\", \"mFACEs\")), \n           Covar = case_when(Var == 1 ~ \"Length\", \n                             TRUE ~ \"Weight\"))\n}\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(Arg, Var, FPC_Num)`\n```\n\n\n:::\n\n```{.r .cell-code}\n# Format mFACEs estimates for comparison\n{\n  FACE_FPC = data.frame(phi_tilde)\n  colnames(FACE_FPC) = paste0(\"phi[\", 1:K, \"](t)\")\n  FACE_FPC$Arg = rep(face_fit$argvals.new, 2)\n  FACE_FPC$Covar = rep(c(\"Length\", \"Weight\"), each = length(face_fit$argvals.new))\n  FACE_FPC = FACE_FPC %>%\n    pivot_longer(-c(Arg, Covar), names_to = \"FuncName\", values_to = \"FACE\") %>%\n    mutate(Method = \"mFACEs\", \n           Method = factor(Method, levels = c(\"MSFAST\", \"mFACEs\")))\n}\n\n# Visualize the results\n{\n  MSFAST_FPC %>%\n    ggplot(aes(x = Arg, color = Method, fill = Method)) + \n    geom_ribbon(aes(ymin = LB, ymax = UB), linewidth = 0, alpha = 0.3) +\n    geom_line(aes(y = Func)) + \n    geom_line(data = FACE_FPC, aes(y = FACE)) +\n    facet_grid(Covar~FuncName, labeller = label_parsed) +\n    theme_bw() + \n    labs(x = \"Age (days)\", y = \"Eigenfunction\")\n}\n```\n\n::: {.cell-output-display}\n![](MSFAST_Vignette_files/figure-html/visualize_mFPCs-1.png){width=1152}\n:::\n:::\n\n\nWe can also examine the eigenvalue posterior distributions for each of the FPCs estimated above, summarized with corresponding credible intervals in the following table. Again, we use the results from mFACEs for comparison.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# MSFAST eigenvalues from score variances\nMSFAST_EV = map(align$Score, function(x) {\n  ev_sample = apply(x, 2, var)\n  return(data.frame(\n    FPC = paste0(\"Phi_\", 1:K, \"(t)\"),\n    EV = ev_sample\n  ))\n}) %>% list_rbind() %>%\n  group_by(FPC) %>%\n  summarize(`Posterior Mean Lambda` = round(mean(EV), 2), \n            `CI Lower` = round(quantile(EV, probs = c(0.025)), 2), \n            `CI Upper` = round(quantile(EV, probs = c(0.975)), 2))\n\n# mFACEs eigenvalues from model output\nFACE_EV = data.frame(FPC = paste0(\"Phi_\", 1:K, \"(t)\"), \n                     EV = round(face_fit$eigenvalues[1:K], 2)) %>%\n  rename(`mFACEs Lambda` = EV)\n\ninner_join(MSFAST_EV, FACE_EV, by = \"FPC\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 5\n  FPC      `Posterior Mean Lambda` `CI Lower` `CI Upper` `mFACEs Lambda`\n  <chr>                      <dbl>      <dbl>      <dbl>           <dbl>\n1 Phi_1(t)                    1.46       1.37       1.55            1.37\n2 Phi_2(t)                    0.24       0.21       0.27            0.35\n3 Phi_3(t)                    0.18       0.16       0.21            0.1 \n4 Phi_4(t)                    0.2        0.14       0.28            0.04\n```\n\n\n:::\n:::\n\n\nAs can be seen above, MSFAST does not agree with mFACEs on the variability explained in the later FPCs, particularly $\\boldsymbol{\\Phi}_3(t)$ and $\\boldsymbol{\\Phi}_4(t)$. Given the tendency of MSFAST to better recover lower signal FPCs, this descrepancy is likely cause for re-ordering of the FPCs during visualization.\n\n## Dynamic Prediction\n\nWe aim to predict the latent trajectories for the two held-out participants. We iteratively update predictions using these subjects' data observed up to 150, 300, and 450 days, mimicking the dynamic prediction task. In all cases, we limit trajectory predictions to 500 days, as there is little data to draw from past this point. To form these predictions, we will need to first define relevant constants.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Predict using data up to 150, 300, and 450 days\nthresholds = 1:3 * 150\n\n# Predict trajectory only up to 500 days\nmax_project = 500\n\n# Object containing posterior samples\nsamples = extract(fit_joint)\n\n# Basis matrix for FPCs when P = 2\nkB = kronecker(diag(P), basis_mat)\n\n# Number of unique observed time points\nM = nrow(basis_mat)\n```\n:::\n\n\nWe can now actually form the trajectory predictions by sampling the subject-specific scores given their available data and the posterior samples of the population-level parameters.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrajectories = map(thresholds, function(age_thresh) { # Predictions at each threshold\n  sub_traj = map(for_prediction, function(sid) { # Predictions for each participant\n    \n    # Reformat data and standardize\n    subset = content_predict %>%\n      filter(Arg <= age_thresh & id == sid) %>%\n      pivot_longer(-c(id, Arg, S), names_to = \"Metric\", values_to = \"Val\") %>%\n      mutate(Var = case_when(Metric == \"zlen\" ~ 1,\n                             TRUE ~ 2)) %>%\n      left_join(data_list$consts, by = \"Var\") %>%\n      mutate(Val = (Val - mu_Y) / sd_Y)\n    \n    # Structure observations\n    Yi = list(length = subset %>% \n                filter(Metric == \"zlen\") %>%\n                pull(Val),\n              weight = subset %>%\n                filter(Metric == \"zwei\") %>%\n                pull(Val))\n    \n    # Orthogonal spline evaluated at the observed points\n    Bi = list(length = basis_mat[subset %>% filter(Metric == \"zlen\") %>% pull(S), ], \n              weight = basis_mat[subset %>% filter(Metric == \"zwei\") %>% pull(S), ])\n    \n    # Sample the scores conditional on population estimates and available data\n    scores = sample_scores(Yi, Bi, samples) %>%\n      select(-c(Sample)) %>%\n      as.matrix()\n    \n    # Calculate trajectories from sampled scores and population-level samples\n    person_traj = map(1:dim(scores)[1], function(x) {\n      smooths = kB %*% (samples$w_mu[x,] + samples$Psi[x, , ] %*% scores[x, ])\n      \n      return(data.frame(Sample = x, Arg = domain,\n                        zlen = smooths[1:M],\n                        zwei = smooths[(M + 1):(2 * M)]))\n    }) %>% list_rbind() %>%\n      pivot_longer(-c(Arg, Sample),\n                   names_to = \"Metric\",\n                   values_to = \"Traj\")\n    \n    return(person_traj %>% mutate(id = sid))\n  }) %>% list_rbind() %>%\n    filter(Arg <= max_project) %>% # Only project to 500 days\n    mutate(Metric = case_when(Metric == \"zlen\" ~ \"Length\",\n                              TRUE ~ \"Weight\"))\n  \n  return(\n    sub_traj %>% # Summarize trajectories by point-wise mean and credible intervals\n      group_by(id, Metric, Arg) %>%\n      summarize(Est = mean(Traj),\n                UB = quantile(Traj, probs = c(0.975)),\n                LB = quantile(Traj, probs = c(0.025))) %>%\n      mutate(id = paste0(\"Ppt. \", id)) %>%\n      mutate(Data_Max = paste0(\"Age~(days)<=\", age_thresh))\n  )\n}) %>%\n  list_rbind()\n```\n:::\n\n\nTo conclude formatting these predictions, we scale them according to the mean and standard deviation of the observed measures and arrange the thresholds for viewing.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrajectories = trajectories %>%\n  mutate(Var = case_when(Metric == \"Length\" ~ 1,\n                         TRUE ~ 2)) %>%\n  left_join(data_list$consts, by = \"Var\") %>%\n  mutate(Est = Est * sd_Y + mu_Y, \n         UB = UB * sd_Y + mu_Y, \n         LB = LB * sd_Y + mu_Y) %>%\n  select(-c(Var)) %>% \n  mutate(Data_Max = factor(Data_Max, levels = paste0(\"Age~(days)<=\", thresholds)))\n```\n:::\n\n\n\nWe next format the raw data for visualization alongside the predicted trajectories.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Corresponding real data\nreal_data = map(thresholds, function(age_thresh) {\n  return(\n    content_predict %>%\n      filter(Arg <= age_thresh) %>%\n      pivot_longer(-c(id, Arg, S), names_to = \"Metric\", values_to = \"Val\") %>%\n      mutate(\n        id = paste0(\"Ppt. \", id),\n        Metric = case_when(Metric == \"zlen\" ~ \"Length\",\n                           TRUE ~ \"Weight\"),\n        Data_Max = paste0(\"Age~(days)<=\", age_thresh)\n      )\n  )\n}) %>%\n  list_rbind() %>%\n  mutate(Data_Max = factor(Data_Max, levels = paste0(\"Age~(days)<=\", thresholds)))\n```\n:::\n\n\nWe can finally visualize the predictions with the data used to form them, with projected trajectories and their uncertainty shifting with the introduction of additional data. Perhaps most noticeably, the credible interval width decreases substantially as more data is included.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrajectories %>%\n  ggplot(aes(x = Arg, group = Metric, color = Metric, fill = Metric)) +\n  geom_line(aes(y = Est)) +\n  geom_ribbon(aes(ymin = LB, ymax = UB), alpha = 0.2) +\n  geom_point(data = real_data, aes(y = Val)) +\n  theme_bw() +\n  scale_x_continuous(lim = c(0, 505)) +\n  coord_cartesian(ylim = c(-2.5, 1)) +\n  facet_grid(Data_Max ~ id,\n             labeller = labeller(Data_Max = label_parsed),\n             scales = \"free_y\") +\n  labs(x = \"Age (days)\", y = \"Z-Score\")\n```\n\n::: {.cell-output-display}\n![](MSFAST_Vignette_files/figure-html/dynamic_prediction_plot-1.png){width=864}\n:::\n:::\n\n\nThis document just visualizes a particular case of applying the \"[MSFAST](../resources/publications/pre_print/sartini_MSFAST_2025.qmd)\" approach to perform fully-Bayesian Functional PCA for sparse, multivariate data. All supporting STAN and R code here is designed to be flexible, such that it may directly be applied to any other similarly structured problem. ",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}