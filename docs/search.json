[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n9/3/25\n\n\nMSFAST: Bayesian Multivariate, Sparse FPCA Vignette\n\n\nJoseph Sartini\n\n\n\n\n8/12/25\n\n\nVisualizing Climate Exposures using Gifs\n\n\nJoseph Sartini\n\n\n\n\n1/31/25\n\n\nSTAN Introduction\n\n\nJoseph Sartini\n\n\n\n\n11/24/24\n\n\nFAST: Bayesian FPCA Vignette\n\n\nJoseph Sartini\n\n\n\n\n11/22/24\n\n\nData Visualization Principles\n\n\nJoseph Sartini\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "pubs.html",
    "href": "pubs.html",
    "title": "Sartini-Stats",
    "section": "",
    "text": "Beyond scalar metrics: functional data analysis of postprandial continuous glucose monitoring in the AEGIS study\n    Sartini, Matabuena, & Gude\n    BMC Medical Research Methodology\n    (2026)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n       Preprint\n    \n    \n    \n  \n\n  \n    Light physical activity and all-cause mortality in US adults across Cardiovascular-Kidney-Metabolic Syndrome Stages\n    Sartini, Rooney, Schrack, McEvoy, Ndumele, Zeger, Selvin, & Fang\n    American Heart Association\n    (2026)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n  \n\n  \n    Fast Bayesian Functional Principal Components Analysis\n    Sartini, Zhou, Selvin, Zeger, & Crainiceanu\n    Computational and Graphical Statistics\n    (2025)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n       Preprint\n    \n    \n    \n    \n       Materials\n    \n    \n  \n\n  \n    Glucose Color Index: Development and Validation of a Novel Measure of the Shape of Glycemic Variability\n    Sartini, Fang, Rooney, Selvin, Coresh, & Zeger\n    Diabetes Science and Technology\n    (2024)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n    \n       Materials\n    \n    \n  \n\n  \n    The evolution of private reputations in information-abundant landscapes\n    Michel-Mata, Kawakatsu, Sartini, Kessinger, Plotkin, & Tarnita\n    Nature\n    (2024)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n    \n       Materials\n    \n    \n  \n\n  \n    The Associations of Mean Glucose and Time in Range from Continuous Glucose Monitoring with HbA1c in Adults with Type 2 Diabetes\n    Selvin, Wang, Rooney, Echouffo-Tcheugui, Fang, Zeger, Sartini, Tang, Coresh, Aurora, & Punjabi\n    Diabetes Technology and Therapeutics\n    (2023)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n  \n\n  \n    Within-person and between-sensor variability in continuous glucose monitoring metrics\n    Selvin, Wang, Rooney, Fang, Echouffo-Tcheugui, Zeger, Sartini, Tang, Coresh, Aurora, & Punjabi\n    Clinical Chemistry\n    (2023)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n  \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "pubs.html#publications",
    "href": "pubs.html#publications",
    "title": "Sartini-Stats",
    "section": "",
    "text": "Beyond scalar metrics: functional data analysis of postprandial continuous glucose monitoring in the AEGIS study\n    Sartini, Matabuena, & Gude\n    BMC Medical Research Methodology\n    (2026)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n       Preprint\n    \n    \n    \n  \n\n  \n    Light physical activity and all-cause mortality in US adults across Cardiovascular-Kidney-Metabolic Syndrome Stages\n    Sartini, Rooney, Schrack, McEvoy, Ndumele, Zeger, Selvin, & Fang\n    American Heart Association\n    (2026)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n  \n\n  \n    Fast Bayesian Functional Principal Components Analysis\n    Sartini, Zhou, Selvin, Zeger, & Crainiceanu\n    Computational and Graphical Statistics\n    (2025)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n       Preprint\n    \n    \n    \n    \n       Materials\n    \n    \n  \n\n  \n    Glucose Color Index: Development and Validation of a Novel Measure of the Shape of Glycemic Variability\n    Sartini, Fang, Rooney, Selvin, Coresh, & Zeger\n    Diabetes Science and Technology\n    (2024)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n    \n       Materials\n    \n    \n  \n\n  \n    The evolution of private reputations in information-abundant landscapes\n    Michel-Mata, Kawakatsu, Sartini, Kessinger, Plotkin, & Tarnita\n    Nature\n    (2024)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n    \n       Materials\n    \n    \n  \n\n  \n    The Associations of Mean Glucose and Time in Range from Continuous Glucose Monitoring with HbA1c in Adults with Type 2 Diabetes\n    Selvin, Wang, Rooney, Echouffo-Tcheugui, Fang, Zeger, Sartini, Tang, Coresh, Aurora, & Punjabi\n    Diabetes Technology and Therapeutics\n    (2023)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n  \n\n  \n    Within-person and between-sensor variability in continuous glucose monitoring metrics\n    Selvin, Wang, Rooney, Fang, Echouffo-Tcheugui, Zeger, Sartini, Tang, Coresh, Aurora, & Punjabi\n    Clinical Chemistry\n    (2023)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n  \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "pubs.html#pre-prints",
    "href": "pubs.html#pre-prints",
    "title": "Sartini-Stats",
    "section": "Pre-Prints",
    "text": "Pre-Prints\n\n\n\n  \n    Bayesian Multivariate Sparse Functional PCA\n    Sartini, Zeger, & Crainiceanu\n    ArXiv\n    (2025)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n       Preprint\n    \n    \n    \n    \n       Materials\n    \n    \n  \n\n  \n    Prediction Inference Using Generalized Functional Mixed Effects Models\n    Zhou, Cui, Sartini, & Crainiceanu\n    ArXiv\n    (2025)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n       Preprint\n    \n    \n    \n  \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Joe Sartini",
    "section": "",
    "text": "I am a 5th year PhD student in the Biostatistics Department at the Johns Hopkins University Bloomberg School of Public Health.\nI am concluding my degree requirements, with tentative graduation in Spring 2026. My PhD advisors are Dr. Scott Zeger and Dr. Ciprian Crainiceanu. For my applied work, I am mentored by Dr. Elizabeth Selvin and Dr. Michael Fang. I previously completed a BSE in Operations Research and Financial Engineering from Princeton University in 2021.\n \n    \n  \n    \n     LinkedIn\n  \n  \n    \n     GitHub\n  \n  \n    \n     Email\n  \n  \n      Bluesky\n  \n\n\n  \n\n\n\n\n\nMotivated by the increasing complexity of data collected by studies employing new physiological monitoring technology (e.g. wearable devices like accelerometry, continuous glucose monitoring, or patch electrocardiograms), my research combines a rigorous statistical approach with computational techniques to produce principled, efficient, and practical software for performing valid inference on structured longitudinal and functional data.\nWhen not working on methods or digging into a dataset, I can usually be found either weightlifting or running.\n\n\n\nStruggling post-Baltimore Marathon"
  },
  {
    "objectID": "cv_host.html",
    "href": "cv_host.html",
    "title": "Sartini-Stats",
    "section": "",
    "text": "Download PDF File\n   \n    Unable to display PDF file. Download instead."
  },
  {
    "objectID": "resources/publications/in_print/selvin_associations_2023.html",
    "href": "resources/publications/in_print/selvin_associations_2023.html",
    "title": "The Associations of Mean Glucose and Time in Range from Continuous Glucose Monitoring with HbA1c in Adults with Type 2 Diabetes",
    "section": "",
    "text": "Selvin, E., Wang, D., Rooney, M. R., Echouffo-Tcheugui, J., Fang, M., Zeger, S., Sartini, J., Tang, O., Coresh, J., Aurora, R. N., & Punjabi, N. M. (2023). The Associations of Mean Glucose and Time in Range from Continuous Glucose Monitoring with HbA1c in Adults with Type 2 Diabetes. Diabetes technology & therapeutics, 25(1), 86–90. https://doi.org/10.1089/dia.2022.0178"
  },
  {
    "objectID": "resources/publications/in_print/selvin_associations_2023.html#citation-apa-7",
    "href": "resources/publications/in_print/selvin_associations_2023.html#citation-apa-7",
    "title": "The Associations of Mean Glucose and Time in Range from Continuous Glucose Monitoring with HbA1c in Adults with Type 2 Diabetes",
    "section": "",
    "text": "Selvin, E., Wang, D., Rooney, M. R., Echouffo-Tcheugui, J., Fang, M., Zeger, S., Sartini, J., Tang, O., Coresh, J., Aurora, R. N., & Punjabi, N. M. (2023). The Associations of Mean Glucose and Time in Range from Continuous Glucose Monitoring with HbA1c in Adults with Type 2 Diabetes. Diabetes technology & therapeutics, 25(1), 86–90. https://doi.org/10.1089/dia.2022.0178"
  },
  {
    "objectID": "resources/publications/in_print/selvin_associations_2023.html#abstract",
    "href": "resources/publications/in_print/selvin_associations_2023.html#abstract",
    "title": "The Associations of Mean Glucose and Time in Range from Continuous Glucose Monitoring with HbA1c in Adults with Type 2 Diabetes",
    "section": "Abstract",
    "text": "Abstract\nAssociations of mean glucose and time in range (70–180 mg/dL) from continuous glucose monitoring (CGM) with HbA1c in adults with type 2 diabetes are not well characterized. We conducted a secondary analysis of 186 participants from the Hyperglycemic Profiles in Obstructive Sleep Apnea (HYPNOS) trial. Participants simultaneously wore Dexcom G4 and Abbott Libre Pro CGM sensors up to 4 weeks. Mean HbA1c was 7.7% (SD, 1.3). There were strong negative Pearson’s correlations of HbA1c with CGM time in range (−0.79, Abbott; −0.81, Dexcom) and strong positive correlations with CGM mean glucose (Dexcom, 0.84; Abbott, 0.82). However, there were large differences in CGM mean glucose (±20 mg/dL) and time in range (±14%) at any given HbA1c value. Mean glucose and HbA1c are strongly correlated in type 2 diabetes patients not taking insulin but discordance is evident at the individual level. Clinicians should expect discordance and use HbA1c and CGM in a complementary manner. ClinicalTrials.gov Identifier: NCT02454153"
  },
  {
    "objectID": "resources/publications/in_print/sartini_BFPCA_2024.html",
    "href": "resources/publications/in_print/sartini_BFPCA_2024.html",
    "title": "Fast Bayesian Functional Principal Components Analysis",
    "section": "",
    "text": "Sartini, J., Zhou, X., Selvin, L., Zeger, S., & Crainiceanu, C. M. (2025). Fast Bayesian Functional Principal Components Analysis. Journal of Computational and Graphical Statistics. https://www.tandfonline.com/doi/abs/10.1080/10618600.2025.2592768"
  },
  {
    "objectID": "resources/publications/in_print/sartini_BFPCA_2024.html#citation-apa-7",
    "href": "resources/publications/in_print/sartini_BFPCA_2024.html#citation-apa-7",
    "title": "Fast Bayesian Functional Principal Components Analysis",
    "section": "",
    "text": "Sartini, J., Zhou, X., Selvin, L., Zeger, S., & Crainiceanu, C. M. (2025). Fast Bayesian Functional Principal Components Analysis. Journal of Computational and Graphical Statistics. https://www.tandfonline.com/doi/abs/10.1080/10618600.2025.2592768"
  },
  {
    "objectID": "resources/publications/in_print/sartini_BFPCA_2024.html#abstract",
    "href": "resources/publications/in_print/sartini_BFPCA_2024.html#abstract",
    "title": "Fast Bayesian Functional Principal Components Analysis",
    "section": "Abstract",
    "text": "Abstract\nFunctional Principal Components Analysis (FPCA) is a widely used analytic tool for dimension reduction of functional data. Traditional implementations of FPCA estimate the principal components from the data, then treat these estimates as fixed in subsequent analyses. To account for the uncertainty of PC estimates, we propose FAST, a fully-Bayesian FPCA with three core components: (1) projection of eigenfunctions onto an orthonormal spline basis; (2) efficient sampling of the orthonormal spline coefficient matrix using a parameter expansion scheme based on polar decomposition; and (3) ordering eigenvalues during sampling. Extensive simulation studies show that FAST is very stable and performs better compared to existing methods. FAST is motivated by and applied to a study of the variability in mealtime glucose from the Dietary Approaches to Stop Hypertension for Diabetes Continuous Glucose Monitoring (DASH4D CGM) study. All relevant STAN code and simulation routines are available as supplementary material."
  },
  {
    "objectID": "resources/publications/in_print/matabuena_multilevel_2024.html",
    "href": "resources/publications/in_print/matabuena_multilevel_2024.html",
    "title": "Beyond scalar metrics: functional data analysis of postprandial continuous glucose monitoring in the AEGIS study",
    "section": "",
    "text": "Matabuena, M., Sartini, J. & Gude, F. Beyond scalar metrics: functional data analysis of postprandial continuous glucose monitoring in the AEGIS study. BMC Med Res Methodol (2026). https://doi.org/10.1186/s12874-025-02748-2"
  },
  {
    "objectID": "resources/publications/in_print/matabuena_multilevel_2024.html#citation-apa",
    "href": "resources/publications/in_print/matabuena_multilevel_2024.html#citation-apa",
    "title": "Beyond scalar metrics: functional data analysis of postprandial continuous glucose monitoring in the AEGIS study",
    "section": "",
    "text": "Matabuena, M., Sartini, J. & Gude, F. Beyond scalar metrics: functional data analysis of postprandial continuous glucose monitoring in the AEGIS study. BMC Med Res Methodol (2026). https://doi.org/10.1186/s12874-025-02748-2"
  },
  {
    "objectID": "resources/publications/in_print/matabuena_multilevel_2024.html#abstract",
    "href": "resources/publications/in_print/matabuena_multilevel_2024.html#abstract",
    "title": "Beyond scalar metrics: functional data analysis of postprandial continuous glucose monitoring in the AEGIS study",
    "section": "Abstract",
    "text": "Abstract\nPurpose: Postprandial glucose, collected through continuous glucose monitoring (CGM), has established clinical relevance in assessing metabolic capacity and informing diet prescriptions. However, most studies of postprandial glucose summarize these data into scalar values, such as 2-hour area under the curve (AUC) or 2-hour peak glucose. We propose analyzing the full CGM time-series trajectories to provide more detailed insights. Given the smooth dynamics of glucose metabolism, the resulting data are inherently functional, with hierarchical structure when there are multiple time series per participant.\nMethods: We consider multilevel functional data analysis (FDA) techniques to analyze postprandial CGM trajectories, applying these methods to data from participants without diabetes in the AEGIS study. The AEGIS study collected meal timing and nutrient composition during periods the participants wore CGM devices. We illustrate the utility of FDA methods to characterize postprandial CGM variability and to explore the associations between dietary/patient characteristics and CGM over the postprandial period. We introduce an extension of the R-squared (\\(R^2\\)) metric to hierarchical functional models to quantify variability explained in this context.\nResults: The FDA models indicate that, for many nutrients, the effect of dietary composition varies throughout the 6-hour post-prandial temporal window. For example, fiber blunts the postprandial glucose response 90 minutes after the meal, while fats reduce the response during the first 50 minutes. In addition, metabolic responses to dietary intake differ between normoglycemic and prediabetic individuals as expected.\nConclusion: Analyzing postprandial glucose responses with functional methods yields temporal insights that traditional scalar approaches cannot capture. Stratifying the analysis by glycemic status (normoglycemic vs. prediabetes) also provides novel findings.}"
  },
  {
    "objectID": "resources/publications/pre_print/zhou_prediction_2025.html",
    "href": "resources/publications/pre_print/zhou_prediction_2025.html",
    "title": "Prediction Inference Using Generalized Functional Mixed Effects Models",
    "section": "",
    "text": "Citation (APA 7)\nZhou, X., Cui, E., Sartini, J., & Crainiceanu, C. (2025). Prediction Inference Using Generalized Functional Mixed Effects Models (arXiv:2501.07842). arXiv. https://doi.org/10.48550/arXiv.2501.07842\nAbstract\nWe introduce inferential methods for prediction based on functional random effects in generalized functional mixed effects models. This is similar to the inference for random effects in generalized linear mixed effects models (GLMMs), but for functional instead of scalar outcomes. The method combines: (1) local GLMMs to extract initial estimators of the functional random components on the linear predictor scale; (2) structural functional principal components analysis (SFPCA) for dimension reduction; and (3) global Bayesian multilevel model conditional on the eigenfunctions for inference on the functional random effects. Extensive simulations demonstrate excellent coverage properties of credible intervals for the functional random effects in a variety of scenarios and for different data sizes. To our knowledge, this is the first time such simulations are conducted and reported, likely because prediction inference was not viewed as a priority and existing methods are too slow to calculate coverage. Methods are implemented in a reproducible R package and demonstrated using the NHANES 2011-2014 accelerometry data."
  },
  {
    "objectID": "posts/Gifs.html",
    "href": "posts/Gifs.html",
    "title": "Visualizing Climate Exposures using Gifs",
    "section": "",
    "text": "library(GSODR)\nlibrary(tidyverse)\nlibrary(gifski)\nlibrary(gganimate)"
  },
  {
    "objectID": "posts/Gifs.html#introduction",
    "href": "posts/Gifs.html#introduction",
    "title": "Visualizing Climate Exposures using Gifs",
    "section": "Introduction",
    "text": "Introduction\nThe goal of this document is to present how to use some helpful animation tools within R (the gifski and gganimate packages) for the purposes of visualizing periodic or seasonal time series data as it varies over the course of a standard epoch. This is useful within a number of contexts, for example when working to understand climate-related exposures over the course of the year. These exposures have consistent seasonal patterns which repeat over the course of each year, so we can aggregate over years and subjects/locations to form estimates of expected exposure over time within any desired window. Animation then allows us to examine how this expected exposure differs as the year progresses. We procede with an example based on the Global Surface Summary of Day (GSOD) data through the corresponding API in the GSODR package."
  },
  {
    "objectID": "posts/Gifs.html#gsod-data",
    "href": "posts/Gifs.html#gsod-data",
    "title": "Visualizing Climate Exposures using Gifs",
    "section": "GSOD Data",
    "text": "GSOD Data\nThe GSOD API provides the “get_GSOD()” function which can be used to pull climate information collected by a subset of the GSOD stations. Here, I have selected Station 723400-99999, which is a Weather Service station in Little Rock, Arkansas, near where I grew up. We collect data between 1990-1995, focusing on humidity as indicated by the dew point (labelled “DEWP” in this dataset, measured in degrees Celsius). This choice of outcome was purely motivated by my own past experience enduring the humidity of my home state.\n\nLR_GSOD = get_GSOD(years = 1990:1995, station = \"723400-99999\") %&gt;%\n    mutate(wdate = ymd(YEARMODA)) %&gt;%\n    rename(dewpoint = DEWP) %&gt;%\n    select(wdate, dewpoint) %&gt;%\n    drop_na()"
  },
  {
    "objectID": "posts/Gifs.html#stationary-visualization-of-gsod-data",
    "href": "posts/Gifs.html#stationary-visualization-of-gsod-data",
    "title": "Visualizing Climate Exposures using Gifs",
    "section": "Stationary Visualization of GSOD Data",
    "text": "Stationary Visualization of GSOD Data\nWe can first create a simple visualization of this time series data, using a point plot with smoothing line to understand (seasonal) trends and day-to-day variability after adjusting for these trends.\n\nLR_GSOD %&gt;%\n  ggplot(aes(x = wdate, y = dewpoint)) + \n  geom_point(alpha = 0.4) +\n  geom_smooth(se = F, color = \"steelblue\", method = \"gam\", \n              formula = y ~ s(x, bs = \"cs\", k = 35)) + \n  theme_bw() + \n  labs(x = \"Date\", y = \"Dewpoint (°C)\")"
  },
  {
    "objectID": "posts/Gifs.html#example-animation",
    "href": "posts/Gifs.html#example-animation",
    "title": "Visualizing Climate Exposures using Gifs",
    "section": "Example Animation",
    "text": "Example Animation\nWhile the above visualization is sufficient for many applications, what about understanding how patterns of dew point over a fixed period, say 6 months, change as one moves through the year? This could be done by sliding a window over the above plot and juxtaposing the visualizations that result from different window locations. However, creating these windowed visualizations and finding the most interesting contrasts can be time consuming.\nAs an alternative, we can create an animation which demonstrates the evolution of this windowed exposure over the course of the year. Using the gifski and gganimate packages, generating this type of visualization is straightforward. We first expand the data, collecting the appropriate window for each possible start date.\n\nwindow_length = 6*4 # in weeks\n\ngif_df = LR_GSOD %&gt;%\n  group_split(wdate) %&gt;%\n  map(function(x){\n    sday = first(x$wdate)\n    \n    sub_data = LR_GSOD %&gt;%\n      mutate(dt = as.numeric(difftime(wdate, sday, units = \"weeks\"))) %&gt;%\n      filter(dt &gt;= 0 & dt &lt;= window_length)\n    \n    sub_data$month_start = month(sday)\n    sub_data$day_start = mday(sday)\n    \n    return(sub_data)\n  }) %&gt;% \n    list_rbind() %&gt;%\n    mutate(day_idx = ymd(\"1999-12-31\") + months(month_start) + days(day_start))\n\ngraph1 = gif_df %&gt;%\n  ggplot(aes(x = dt, y = dewpoint)) + \n  geom_point(alpha = 0.4, size = 3) +\n  geom_smooth(se = F, color = \"steelblue\") +\n  theme_bw() + \n  labs(x = \"Week of Exposure Window\", y = \"Dewpoint (°C)\")\n\ngraph1.animation = graph1 + \n  transition_time(day_idx) + \n  labs(subtitle = \"Start of Window: {format(frame_time, '%m-%d')}\")\n\nanimate(graph1.animation, height = 500, width = 900, duration = 20, \n        end_pause = 1, nframes = 200)\nanim_save(\"../resources/images/Gif_Exposure.gif\")\n\nWe can now view the saved animation through embedding:\n\n\n\nThe exposure animation generated in R.\n\n\nWhile this type of animation is helpful in and of itself, it is best combined with similar animations for related outcome variables and other covariates of interest. Dynamic visualization techniques such as this are an important addition to any statisticians toolkit, and we should not hesitate to leverage them (so long as it is appropriate, of course)."
  },
  {
    "objectID": "posts/STAN_Intro.html#what-is-stan",
    "href": "posts/STAN_Intro.html#what-is-stan",
    "title": "STAN Introduction",
    "section": "What is STAN?",
    "text": "What is STAN?\n\n\nBayesian probabilistic programming language\nMultiple posterior sampling routines\n\nHamiltonian Monte Carlo\nVariational Inference\nLaplace approximation\n\nBased on C++\nInterfaces with Python, Julia, R, and Unix Shell"
  },
  {
    "objectID": "posts/STAN_Intro.html#structure-of-a-stan-script",
    "href": "posts/STAN_Intro.html#structure-of-a-stan-script",
    "title": "STAN Introduction",
    "section": "Structure of a STAN Script",
    "text": "Structure of a STAN Script\n\nfunctions {\n  // ... function declarations and definitions ...\n}\ndata {\n  // ... declarations ...\n}\ntransformed data {\n   // ... declarations ... statements ...\n}\nparameters {\n   // ... declarations ...\n}\ntransformed parameters {\n   // ... declarations ... statements ...\n}\nmodel {\n   // ... declarations ... statements ...\n}\ngenerated quantities {\n   // ... declarations ... statements ...\n}\n\n\nAll blocks are optional, an empty string is actually a valid STAN code. Order is important, they must be in the above order Variables have scope over all subsequent blocks"
  },
  {
    "objectID": "posts/STAN_Intro.html#section---functions",
    "href": "posts/STAN_Intro.html#section---functions",
    "title": "STAN Introduction",
    "section": "Section - functions",
    "text": "Section - functions\n\n\nComplex indexing\n\nSparsely observed data\n\nGenerating quantities/structures\n\nSplines, etc.\n\nSuffixes for particular functions\n\nContaining RNG: “_rng”\nModifying target density: “_lp”\n\n\n\n\nRNG functions can only be used on data/generated quantities"
  },
  {
    "objectID": "posts/STAN_Intro.html#section---data",
    "href": "posts/STAN_Intro.html#section---data",
    "title": "STAN Introduction",
    "section": "Section - data",
    "text": "Section - data\n\n\nLikelihood data\n\nIndexing arrays\n\nAll constants\n\nArray extents\n\nCommonly used linear transforms\n\n\n\nOften need more information in this block than you think to fully specify the model."
  },
  {
    "objectID": "posts/STAN_Intro.html#section---transformed-data",
    "href": "posts/STAN_Intro.html#section---transformed-data",
    "title": "STAN Introduction",
    "section": "Section - transformed data",
    "text": "Section - transformed data\n\n\nFunctions of data variables\nOnly evaluated once\n\nPrior to sampling\n\nHelpful for book-keeping\n\nSimplify data inputs\n\nRandom data sub-samples"
  },
  {
    "objectID": "posts/STAN_Intro.html#section---parameters",
    "href": "posts/STAN_Intro.html#section---parameters",
    "title": "STAN Introduction",
    "section": "Section - parameters",
    "text": "Section - parameters\n\n\nSpecify sampled quantities\n\nVariable names\nExtents\n\nDefinitions only, no statements\nRead from underlying sampler\nCan provide initial values\n\n\n\n\nWill get more into how to provide initial values shortly"
  },
  {
    "objectID": "posts/STAN_Intro.html#section---transformed-parameters",
    "href": "posts/STAN_Intro.html#section---transformed-parameters",
    "title": "STAN Introduction",
    "section": "Section - transformed parameters",
    "text": "Section - transformed parameters\n\n\nDeterministic functions\nPart of target posterior\nEvaluated with each sample\n\nInverse transform\nLog absolute Jacobian\n\nGood for re-parameterization\n\nStability\nLatent modeling\n\n\n\n\n\nCan include data, transformed data, and parameters as inputs\nNeed inverse transform and log absolute Jacobian to be efficient, as they can greatly slow down the sampling process otherwise\nNatural scale vs sampling efficiency (NUTS and standard HMC prefer unconstrained parameters). However, gradient calculations usually dwarf these differences"
  },
  {
    "objectID": "posts/STAN_Intro.html#section---model",
    "href": "posts/STAN_Intro.html#section---model",
    "title": "STAN Introduction",
    "section": "Section - model",
    "text": "Section - model\n\n\nDefine the target posterior\n\nSum of log density functions\n\nPrior distributions on (transformed) parameters\nData/model likelihood\nMost computational expense\nORDER MATTERS\n\n\n\nIt is often important to know which subgroup of operations within the model block is consuming the majority of computation time (after deciding that efficient is insufficient). We will get to how this can be done (do not optimize unless necessary)."
  },
  {
    "objectID": "posts/STAN_Intro.html#section---generated-quantities",
    "href": "posts/STAN_Intro.html#section---generated-quantities",
    "title": "STAN Introduction",
    "section": "Section - generated quantities",
    "text": "Section - generated quantities\n\n\nExecuted after samples are generated\nFunctions of model output\n\nPredictions for new data\nSimulate new data\nExtract posterior estimates\nCalculate model fit criterion"
  },
  {
    "objectID": "posts/STAN_Intro.html#example-model---glm",
    "href": "posts/STAN_Intro.html#example-model---glm",
    "title": "STAN Introduction",
    "section": "Example Model - GLM",
    "text": "Example Model - GLM\n\ndata {\n  int N;  // Number of observations\n  int P;  // Number of fixed effect covariates\n  \n  array[N] int&lt;lower=0, upper=1&gt; Y;  // Binary outcomes\n  matrix[N, P] X;                    // Fixed effects design matrix\n}\nparameters {\n   vector[P] beta;  // Coefficients\n}\nmodel {\n   Y ~ bernoulli_logit(X * beta);\n}\n\n\nWhile there is no explicit prior on beta here, that just means that STAN is choosing the equivalent to a uniform prior under the hood"
  },
  {
    "objectID": "posts/STAN_Intro.html#running-the-model-in-r",
    "href": "posts/STAN_Intro.html#running-the-model-in-r",
    "title": "STAN Introduction",
    "section": "Running the Model in R",
    "text": "Running the Model in R\n\nfit_df = mtcars %&gt;%\n  mutate(Efficient = case_when(mpg &gt;= median(mpg) ~ 1,\n                               TRUE ~ 0)) %&gt;%\n  mutate(am = as.factor(am))\nfit_matrix = model.matrix(~cyl + disp + hp + drat + wt + am, fit_df)\n\ndata_list = list(N = nrow(mtcars), P = ncol(fit_matrix), \n                 Y = fit_df$Efficient, X = fit_matrix)\n\nmodel = sampling(\n  first_model, \n  data = data_list, \n  chains = 4, \n  iter = 1000, \n  warmup = 500, \n  # init = ,\n  # control = list(adapt_delta = , \n  #                max_treedepth = , \n  #                stepsize_jitter = ), \n  verbose = F,\n  refresh = 0\n)"
  },
  {
    "objectID": "posts/STAN_Intro.html#convergence-monitoring",
    "href": "posts/STAN_Intro.html#convergence-monitoring",
    "title": "STAN Introduction",
    "section": "Convergence Monitoring",
    "text": "Convergence Monitoring\n\ncheck_hmc_diagnostics(model)\n\n\nDivergences:\n\n\n0 of 2000 iterations ended with a divergence.\n\n\n\nTree depth:\n\n\n1212 of 2000 iterations saturated the maximum tree depth of 10 (60.6%).\nTry increasing 'max_treedepth' to avoid saturation.\n\n\n\nEnergy:\n\n\nE-BFMI indicated no pathological behavior.\n\n\n\nsummary(model)$summary[,\"Rhat\"]\n\n beta[1]  beta[2]  beta[3]  beta[4]  beta[5]  beta[6]  beta[7]     lp__ \n2.365263 2.081568 2.424803 2.459833 2.446590 1.643589 2.438779 1.039459"
  },
  {
    "objectID": "posts/STAN_Intro.html#hamiltonian-monte-carlo",
    "href": "posts/STAN_Intro.html#hamiltonian-monte-carlo",
    "title": "STAN Introduction",
    "section": "Hamiltonian Monte Carlo",
    "text": "Hamiltonian Monte Carlo\n\nHMC Visualization: By Justinkunimune - github.com/jkunimune/hamiltonian-mc, CC0"
  },
  {
    "objectID": "posts/STAN_Intro.html#hamiltonian-monte-carlo-continued",
    "href": "posts/STAN_Intro.html#hamiltonian-monte-carlo-continued",
    "title": "STAN Introduction",
    "section": "Hamiltonian Monte Carlo Continued",
    "text": "Hamiltonian Monte Carlo Continued\n\n\nVersion of Metropolis-Hastings\nHamiltonian Dynamics used to propose next state\n\nTrajectory with momentum\nDistribution \\(\\approx\\) potential energy field\nLeapfrog integrator stepwise approximation\n\nMomentum: reduced correlation between samples\nEnergy conservation: high acceptance probability\n\n\n\n\nLeapfrog integrator uses model gradient to take steps, why it is important to keep this efficient (analytical gradients built-in by STAN for many things)\nUse MH step to compensate for numerical issues in the Leapfrog algorithm, but acceptance probability should be high if things go well (not needed in perfect world)"
  },
  {
    "objectID": "posts/STAN_Intro.html#divergences",
    "href": "posts/STAN_Intro.html#divergences",
    "title": "STAN Introduction",
    "section": "Divergences",
    "text": "Divergences\n\n\nSimulated trajectory \\(\\neq\\) true trajectory\nGlobal step size \\(&gt;\\) true posterior geometry resolution\n\nLeapfrog first order approximataion\n\nHamiltonian departs from initial value\n\nTotal energy (kinetic + potential)\nShould be preserved along trajectory\n\nSampler WILL NOT accept samples after divergence"
  },
  {
    "objectID": "posts/STAN_Intro.html#tree-depth-warnings",
    "href": "posts/STAN_Intro.html#tree-depth-warnings",
    "title": "STAN Introduction",
    "section": "Tree Depth Warnings",
    "text": "Tree Depth Warnings\n\n\nTree depth controls number of simulation steps\n\n\\(\\leq 2^{max\\_treedepth}\\) steps\n\nPrimarily an efficiency concern\nGenerally recommended to not increase\n\nOften model misspecification"
  },
  {
    "objectID": "posts/STAN_Intro.html#est.-bayesian-fraction-of-miss.-info.",
    "href": "posts/STAN_Intro.html#est.-bayesian-fraction-of-miss.-info.",
    "title": "STAN Introduction",
    "section": "Est. Bayesian Fraction of Miss. Info.",
    "text": "Est. Bayesian Fraction of Miss. Info.\n\n\nPosterior decomposes into energy equivalence classes\nLow EBFMI indicates getting “stuck” in energy sets\n\nSTAN monitors energy during sampling\n\nInsufficiently exploring the posterior\n\nTails too large, etc"
  },
  {
    "objectID": "posts/STAN_Intro.html#geometric-intuition",
    "href": "posts/STAN_Intro.html#geometric-intuition",
    "title": "STAN Introduction",
    "section": "Geometric Intuition",
    "text": "Geometric Intuition"
  },
  {
    "objectID": "posts/STAN_Intro.html#return-to-our-example-model-outputs",
    "href": "posts/STAN_Intro.html#return-to-our-example-model-outputs",
    "title": "STAN Introduction",
    "section": "Return to our Example: Model Outputs",
    "text": "Return to our Example: Model Outputs\n\nsamples = extract(model)\n\nbeta_0 = map(1:dim(samples$beta)[1], function(x){\n  return(data.frame(beta0 = samples$beta[x,1], \n                    Sample = x))\n}) %&gt;% list_rbind()"
  },
  {
    "objectID": "posts/STAN_Intro.html#model-outputs-2",
    "href": "posts/STAN_Intro.html#model-outputs-2",
    "title": "STAN Introduction",
    "section": "Model Outputs (2)",
    "text": "Model Outputs (2)\n\nsamples = extract(model, \"beta\", permuted = FALSE)\n\nbeta_0 = map(1:dim(samples)[1], function(x){\n  return(data.frame(beta0 = samples[x,,1], \n                    Chain = 1:4, \n                    sample = x))\n}) %&gt;% list_rbind()"
  },
  {
    "objectID": "posts/STAN_Intro.html#shinystan-debugging",
    "href": "posts/STAN_Intro.html#shinystan-debugging",
    "title": "STAN Introduction",
    "section": "ShinySTAN Debugging",
    "text": "ShinySTAN Debugging\n\nlaunch_shinystan(model)"
  },
  {
    "objectID": "posts/STAN_Intro.html#shinystan---nuts-summary",
    "href": "posts/STAN_Intro.html#shinystan---nuts-summary",
    "title": "STAN Introduction",
    "section": "ShinySTAN - NUTS Summary",
    "text": "ShinySTAN - NUTS Summary"
  },
  {
    "objectID": "posts/STAN_Intro.html#shinystan---divergences",
    "href": "posts/STAN_Intro.html#shinystan---divergences",
    "title": "STAN Introduction",
    "section": "ShinySTAN - Divergences",
    "text": "ShinySTAN - Divergences"
  },
  {
    "objectID": "posts/STAN_Intro.html#shinystan---treedepth",
    "href": "posts/STAN_Intro.html#shinystan---treedepth",
    "title": "STAN Introduction",
    "section": "ShinySTAN - Treedepth",
    "text": "ShinySTAN - Treedepth"
  },
  {
    "objectID": "posts/STAN_Intro.html#shinystan---energy",
    "href": "posts/STAN_Intro.html#shinystan---energy",
    "title": "STAN Introduction",
    "section": "ShinySTAN - Energy",
    "text": "ShinySTAN - Energy"
  },
  {
    "objectID": "posts/STAN_Intro.html#shinystan---autocorrelation",
    "href": "posts/STAN_Intro.html#shinystan---autocorrelation",
    "title": "STAN Introduction",
    "section": "ShinySTAN - Autocorrelation",
    "text": "ShinySTAN - Autocorrelation"
  },
  {
    "objectID": "posts/STAN_Intro.html#how-to-update-the-model",
    "href": "posts/STAN_Intro.html#how-to-update-the-model",
    "title": "STAN Introduction",
    "section": "How to Update the Model",
    "text": "How to Update the Model\n\ndata {\n  int N;  // Number of observations\n  int P;  // Number of fixed effect covariates\n  \n  array[N] int&lt;lower=0, upper=1&gt; Y;  // Binary outcomes\n  matrix[N, P] X;                    // Fixed effects design matrix\n}\ntransformed data {\n  matrix[N, P] Q_coef = qr_thin_Q(X) * sqrt(N-1);\n  matrix[P, P] R_coef = qr_thin_R(X) / sqrt(N-1);\n  matrix[P, P] R_coef_inv = inverse(R_coef);\n}\nparameters {\n  vector[P] theta;  // Coefficients\n}\nmodel {\n  theta ~ normal(0, 100);\n  Y ~ bernoulli_logit(Q_coef * theta);\n}\ngenerated quantities {\n  vector[P] beta = R_coef_inv * theta;\n}"
  },
  {
    "objectID": "posts/STAN_Intro.html#running-the-updated-model",
    "href": "posts/STAN_Intro.html#running-the-updated-model",
    "title": "STAN Introduction",
    "section": "Running the Updated Model",
    "text": "Running the Updated Model\n\nmodel = sampling(\n  second_model, \n  data = data_list, \n  chains = 4, \n  iter = 2500, \n  warmup = 1000, \n  control = list(adapt_delta = 0.95),\n  verbose = F,\n  refresh = 0\n)"
  },
  {
    "objectID": "posts/STAN_Intro.html#updated-model-performance",
    "href": "posts/STAN_Intro.html#updated-model-performance",
    "title": "STAN Introduction",
    "section": "Updated Model Performance",
    "text": "Updated Model Performance\n\ncheck_hmc_diagnostics(model)\n\n\nDivergences:\n\n\n0 of 6000 iterations ended with a divergence.\n\n\n\nTree depth:\n\n\n0 of 6000 iterations saturated the maximum tree depth of 10.\n\n\n\nEnergy:\n\n\nE-BFMI indicated no pathological behavior.\n\n\n\nsummary(model)$summary[,\"Rhat\"]\n\ntheta[1] theta[2] theta[3] theta[4] theta[5] theta[6] theta[7]  beta[1] \n1.003796 1.003760 1.001931 1.003562 1.003605 1.003334 1.003570 1.002406 \n beta[2]  beta[3]  beta[4]  beta[5]  beta[6]  beta[7]     lp__ \n1.001364 1.003667 1.003591 1.003552 1.000757 1.003570 1.001324"
  },
  {
    "objectID": "posts/STAN_Intro.html#updated-model-visualization",
    "href": "posts/STAN_Intro.html#updated-model-visualization",
    "title": "STAN Introduction",
    "section": "Updated Model Visualization",
    "text": "Updated Model Visualization"
  },
  {
    "objectID": "posts/STAN_Intro.html#updated-geometry",
    "href": "posts/STAN_Intro.html#updated-geometry",
    "title": "STAN Introduction",
    "section": "Updated Geometry",
    "text": "Updated Geometry"
  },
  {
    "objectID": "posts/STAN_Intro.html#profiling-the-model-with-cmdstanr-1",
    "href": "posts/STAN_Intro.html#profiling-the-model-with-cmdstanr-1",
    "title": "STAN Introduction",
    "section": "Profiling the Model with CmdStanR (1)",
    "text": "Profiling the Model with CmdStanR (1)\n\ndata {\n  int N;  // Number of observations\n  int P;  // Number of fixed effect covariates\n  \n  array[N] int&lt;lower=0, upper=1&gt; Y;  // Binary outcomes\n  matrix[N, P] X;                    // Fixed effects design matrix\n}\ntransformed data {\n  matrix[N, P] Q_coef = qr_thin_Q(X) * sqrt(N-1);\n  matrix[P, P] R_coef = qr_thin_R(X) / sqrt(N-1);\n  matrix[P, P] R_coef_inv = inverse(R_coef);\n}\nparameters {\n  vector[P] theta;  // Coefficients\n}\nmodel {\n  profile(\"Priors\") {\n    target += normal_lpdf(theta| 0, 100);\n  }\n  profile(\"Likelihood\") {\n    target += bernoulli_logit_lpmf(Y| Q_coef * theta);\n  }\n}\ngenerated quantities {\n  profile(\"Generated\") {\n    vector[P] beta = R_coef_inv * theta;\n  }\n}"
  },
  {
    "objectID": "posts/STAN_Intro.html#profiling-the-model-with-cmdstanr-2",
    "href": "posts/STAN_Intro.html#profiling-the-model-with-cmdstanr-2",
    "title": "STAN Introduction",
    "section": "Profiling the Model with CmdStanR (2)",
    "text": "Profiling the Model with CmdStanR (2)\n\nmodel = cmdstan_model(\"Profile_Mod.stan\")\nfit = model$sample(data = data_list, chains = 1)\nfit$profiles()[[1]][,c(1,3,4,5,8)]\n\n\n\n        name  total_time forward_time reverse_time autodiff_calls\n1  Generated 0.000175152  0.000175152   0.00000000              0\n2 Likelihood 0.145845000  0.116126000   0.02971880         170759\n3     Priors 0.026700700  0.023262300   0.00343839         170759"
  },
  {
    "objectID": "posts/STAN_Intro.html#resource-links",
    "href": "posts/STAN_Intro.html#resource-links",
    "title": "STAN Introduction",
    "section": "Resource Links",
    "text": "Resource Links\n\nSTAN Manual\nIntroduction to HMC\nBayesian Workflow\n\n\nIntro to HMC by Michael Betancourt\nBayesian Workflow by Gelman et. al."
  },
  {
    "objectID": "posts/MSFAST_Vignette.html",
    "href": "posts/MSFAST_Vignette.html",
    "title": "MSFAST: Bayesian Multivariate, Sparse FPCA Vignette",
    "section": "",
    "text": "# General helper functions\nsource(\"MSFAST_support/Libs.R\")\nsource(\"MSFAST_support/Bases.R\")\nsource(\"MSFAST_support/PostProcess.R\")\nsource(\"MSFAST_support/Convergence.R\")\n\n# Supporting functions for MSFAST\nsource(\"MSFAST_support/MSFAST_Help.R\")\nsource(\"MSFAST_support/Resample_Scores.R\")"
  },
  {
    "objectID": "posts/MSFAST_Vignette.html#read-in-the-content-child-growth-data",
    "href": "posts/MSFAST_Vignette.html#read-in-the-content-child-growth-data",
    "title": "MSFAST: Bayesian Multivariate, Sparse FPCA Vignette",
    "section": "Read in the CONTENT Child Growth Data",
    "text": "Read in the CONTENT Child Growth Data\nFor this vignette, we analyze a subset (\\(N = 197\\)) of child growth data from the CONTENT study as included in the “refund” package. As part of CONTENT, multiple growth measures were taken at the same time for each participant and sparsely across individuals.\nCONTENT was conducted between May 2007 and February 2011 in Las Pampas de San Juan Miraflores and Nuevo Paraíso, two peri-urban shanty towns located on the southern edge of Lima City in Peru. The shanty towns had approximately \\(40{,}000\\) residents with \\(25\\)% of the population under the age of \\(5\\) (W. Checkley et al. 1998; William Checkley et al. 2003).\nA simple census was conducted to identify pregnant women and children less than \\(3\\) months old. Eligible newborns and pregnant women were randomly selected and invited to participate in the study (at most one newborn per household). The longitudinal cohort study aimed to assess whether Helicobacter pylori (H. pylori) infection adversely affects the growth in children less than \\(2\\) years of age (Jaganath et al. 2014; Crainiceanu et al. 2024).\nThe study aimed to collect measures weekly until the child was \\(3\\) months old, biweekly between \\(3\\) and \\(11\\) months, and once monthly afterwards. Some visits were missed or canceled, contributing to the sparse data structure.\nWe read in the data using standard Tidyverse syntax, focusing on the length and weight z-scores relative to the age- and sex-specific World Health Organization standards.\n\ndata(content)\n\ncontent = content %&gt;%\n  select(id, ma1fe0, agedays, zlen, zwei)"
  },
  {
    "objectID": "posts/MSFAST_Vignette.html#visualization-of-the-sparse-structure",
    "href": "posts/MSFAST_Vignette.html#visualization-of-the-sparse-structure",
    "title": "MSFAST: Bayesian Multivariate, Sparse FPCA Vignette",
    "section": "Visualization of the Sparse Structure",
    "text": "Visualization of the Sparse Structure\nWe now visualize the observation times by gender for the entire dataset and the observed data for four participants (two randomly chosen and two chosen for holdout to illustrate dynamic prediction). These visualizations borrow strongly from the section in “Functional Data Analysis with R” on sparsely observed functional data, which includes discussion of the CONTENT dataset. The first visualization aims to illustrate the general structure of the sparsity in observations.\n\nset.seed(37578) # Essential for reproducibility\nfor_prediction = c(73, 112) # Participants for dynamic prediction\n\nvis_ppts = c(sample(unique(content %&gt;% filter(ma1fe0 == 0) %&gt;% pull(id)), 1), \n             for_prediction[1], \n             sample(unique(content %&gt;% filter(ma1fe0 == 1) %&gt;% pull(id)), 1), \n             for_prediction[2])\n\ncontent %&gt;%\n  select(id, ma1fe0, agedays) %&gt;%\n  mutate(Gender = case_when(ma1fe0 == 1 ~ \"Male\", \n                            TRUE ~ \"Female\")) %&gt;%\n  group_by(Gender, id) %&gt;%\n  nest(data = agedays) %&gt;%\n  ungroup() %&gt;%\n  group_by(Gender) %&gt;%\n  mutate(pptid = row_number()) %&gt;%\n  ungroup() %&gt;%\n  unnest(data) %&gt;%\n  mutate(coloring = case_when(id %in% vis_ppts ~ \"Observed\", \n                              TRUE ~ \"Excluded\")) %&gt;%\n  ggplot(aes(x = agedays, y = pptid)) + \n  geom_point(aes(color = coloring), size = 1) + \n  theme_bw() + \n  facet_wrap(.~Gender) + \n  scale_color_manual(values = c(\"Observed\" = \"darkorange\", \n                                \"Excluded\" = \"steelblue\")) + \n  labs(x = \"Age (Days)\", y = \"Participant\", title = \"\") +\n  theme(axis.text.y = element_blank(), \n        axis.ticks.y = element_blank(), \n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nFocusing on just four participants, two of each gender highlighted in the above observations plot, we can better visualize the actual bivariate patterns within the data.\n\nlabs = c(paste0(c(\"Female\", \"Male\"), \" Ppt. 1\"), \n         paste0(c(\"Female\", \"Male\"), \" Ppt. 2\"))\ncontent %&gt;%\n  filter(id %in% vis_ppts) %&gt;%\n  mutate(new_id = case_when(id == vis_ppts[1] ~ labs[1], \n                            id == vis_ppts[2] ~ labs[3], \n                            id == vis_ppts[3] ~ labs[2], \n                            TRUE ~ labs[4]), \n         new_id = factor(new_id, levels = labs)) %&gt;%\n  select(new_id, id, agedays, zlen, zwei) %&gt;%\n  pivot_longer(-c(new_id, id, agedays), names_to = \"Measure\", values_to = \"Y\") %&gt;%\n  mutate(Measure = case_when(Measure == \"zlen\" ~ \"Length\", \n                             TRUE ~ \"Weight\")) %&gt;%\n  ggplot(aes(x = agedays, y = Y, group = Measure, color = Measure)) + \n  geom_point() + \n  facet_wrap(.~new_id, ncol = 2) + \n  theme_bw() + \n  labs(x = \"Age (Days)\", y = \"Z-Score\", title = \"\") + \n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "posts/MSFAST_Vignette.html#fitting-msfast",
    "href": "posts/MSFAST_Vignette.html#fitting-msfast",
    "title": "MSFAST: Bayesian Multivariate, Sparse FPCA Vignette",
    "section": "Fitting MSFAST",
    "text": "Fitting MSFAST\nWe first remove two participants from the dataset that will be used to fit the model. We will illustrate dynamic prediction using the data from these participants later.\n\ncontent_fit = content %&gt;%\n  filter(!(id %in% for_prediction)) %&gt;%\n  select(-c(ma1fe0))\n\ncontent_predict = content %&gt;%\n  filter(id %in% for_prediction) %&gt;%\n  select(-c(ma1fe0)) %&gt;%\n  rename(Arg = agedays)\n\nAt this point, we form the input data list required by MSFAST, described in the “Bayesian implementation in STAN” section of the manuscript.\n\n# Pivot to long and adjust names\nfit_df = content_fit %&gt;%\n  pivot_longer(-c(id, agedays),\n               names_to = \"Covar\",\n               values_to = \"Y\") %&gt;%\n  mutate(Var = case_when(Covar == \"zlen\" ~ 1, # Replace names with indices\n                         TRUE ~ 2)) %&gt;%\n  select(-c(Covar)) %&gt;%\n  reset_id() %&gt;% # Reset participant ids to sequential integers\n  rename(Subj = id, Arg = agedays)\n\n# Find observation time indices S and append\nS_df = data.frame(Arg = sort(unique(fit_df$Arg)))\nS_df$S = 1:nrow(S_df)\nfit_df = inner_join(fit_df, S_df, by = \"Arg\")\ncontent_predict = inner_join(content_predict, S_df, by = \"Arg\")\n\n# Translate domain to (0, 1)\ndomain = S_df$Arg\nscaled_domain = (domain - min(domain)) / (max(domain) - min(domain))\n\nN = n_distinct(fit_df$Subj)   # Number of participants\nQ = 20                        # Spline basis dimension\nK = 4                         # Number of principal components\nP = n_distinct(fit_df$Var)    # Number of unique covariates (2 here)\n\n# Function to coalesce inputs (basis is orthogonalized B-splines by default)\ndata_list = MSFAST_datalist(fit_df, N = N, K = K, Q = Q, scaled_domain, \n                            scale = T)\n\nWe can finally fit the model using RSTAN as follows.\n\nfit_joint = stan(\"MSFAST_support/MSFAST.stan\", \n                 data = data_list, \n                 chains = 4, \n                 cores = 4, \n                 warmup = 2000, \n                 iter = 3000, \n                 control = list(max_treedepth = 12))\n\nNote that the above block does not leverage parallelization over covariates through multithreading. To leverage this computational speed-up (after ensuring sufficient available resources), one can use “Sys.setenv(STAN_NUM_THREADS=X)” for \\(\\text{X} &gt; 1\\) and the parallelized STAN implementation."
  },
  {
    "objectID": "posts/MSFAST_Vignette.html#evaluating-fit-and-aligning-results",
    "href": "posts/MSFAST_Vignette.html#evaluating-fit-and-aligning-results",
    "title": "MSFAST: Bayesian Multivariate, Sparse FPCA Vignette",
    "section": "Evaluating Fit and Aligning Results",
    "text": "Evaluating Fit and Aligning Results\nWe first fit mFACEs, extracting the estimates provided by this method to be used as our fixed point \\(\\widetilde{\\boldsymbol{\\Phi}}\\) for the Procrustes-based alignment of posterior FPC samples described in the manuscript.\n\n# Data in list format\nface_data = list(content %&gt;% \n                   filter(!(id %in% for_prediction)) %&gt;%\n                   select(agedays, id, zlen) %&gt;%\n                   rename(argvals = agedays, \n                          subj = id, y = zlen), \n                 content %&gt;%\n                   filter(!(id %in% for_prediction)) %&gt;%\n                   select(agedays, id, zwei) %&gt;%\n                   rename(argvals = agedays, \n                          subj = id, y = zwei))\n\n# Call to function\nface_fit = mface.sparse(face_data, argvals.new = domain, knots = Q-3,\n                        knots.option = \"quantile\", pve = 0.999)\n\n# Extract first K FPC estimates as fixed point matrix\nphi_tilde = face_fit$eigenfunctions[,1:K] \n\nWe next check the Gelman-Rubin statistics for all relevant model components (after alignment). This is done automatically using the “RHat_FAST()” function as follows. This function calculates the median and max RHat observed for each FPC/covariate grouping within parameter families. The results below indicate that all parameters have converged according to the heuristic RHat &lt; 1.05 threshold.\n\nrhats = RHat_FAST(fit_joint,   # RSTAN object \n                  data_list,   # List of constants\n                  data_list$B, # Orthogonal spline basis matrix\n                  phi_tilde)   # Fixed point for rotational alignment\n\n# Scores, grouped by FPC\nrhats$Score\n\n# A tibble: 4 × 3\n  FPC_Num Med_RHat Max_RHat\n  &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n1 FPC 1       1.02     1.04\n2 FPC 2       1.00     1.01\n3 FPC 3       1.00     1.01\n4 FPC 4       1.00     1.02\n\n# FPCs, grouped by FPC/functional component\nrhats$Func\n\n# A tibble: 5 × 3\n  Function Med_RHat Max_RHat\n  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;\n1 FPC 1        1.00     1.01\n2 FPC 2        1.00     1.00\n3 FPC 3        1.00     1.02\n4 FPC 4        1.01     1.03\n5 Mu           1.00     1.00\n\n# Fixed effect smoothing parameters, grouped by covariate\nrhats$Mu_Smoothing\n\n  Function     RHat\n1      Mu1 1.001001\n2      Mu2 1.001592\n\n# FPC smoothing parameters, grouped by FPC and covariate\nrhats$FPC_Smoothing\n\n# A tibble: 8 × 3\n  Var   FPC    RHat\n  &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 Var 1 FPC 1  1.02\n2 Var 1 FPC 2  1.01\n3 Var 1 FPC 3  1.00\n4 Var 1 FPC 4  1.00\n5 Var 2 FPC 1  1.00\n6 Var 2 FPC 2  1.01\n7 Var 2 FPC 3  1.01\n8 Var 2 FPC 4  1.00\n\n# Variance components, no grouping\nrhats$Variances\n\n   Element     RHat\n1 Lambda_1 1.000116\n2 Lambda_2 1.001444\n3 Lambda_3 1.007298\n4 Lambda_4 1.027927\n5   Sigma2 1.000165\n\n\nWe can extract and align the posterior samples, leveraging the Procrustes-based procedure described in the manuscript, using the provided suite of post-processing functions as follows.\n\n# Can adjust the observation points at which inference is performed\nbasis_mat = FAST_B(\"B\", Q, scaled_domain)\n\n# Extract FPCs, corresponding weights, fixed effect weights, and scores\nobjects = FAST_extract(fit_joint, basis_mat, data_list)\n\n# Align samples using Procrustes-based procedure\nalign = procrust_WEI(objects$Weights, basis_mat, P, phi_tilde, objects$Score)\n\n# Extract FPC estimates and credible intervals\nEF_ests = FPC_Est_WEI(align$Weight, basis_mat, P, domain, phi_tilde)\nEF_bounds = FPC_CI(align$EF, domain, P)\n\nWe next evaluate the proportion of global variability explained to ensure the number of FPCs \\(K\\) was chosen appropriately. The final values are above 95% for all samples, seeming to indicate that \\(K = 4\\) is sufficient for this data.\n\n# True data in sparse matrix form\ndata_matrix = fit_df %&gt;%\n  pivot_wider(names_from = Subj, values_from = Y) %&gt;%\n  arrange(Var, Arg) %&gt;%\n  select(-c(Var, Arg, S)) %&gt;%\n  as.matrix() %&gt;%\n  t()\nmask = is.na(data_matrix)\ndata_var = var(data_matrix[!mask])\n\n# Modeled smooths in sparse matrix of dim. samples x ppts x obs\nsamples_matrix = Smooth_Raw(objects$Mu, align$EF, align$Score, data_list)\nn_samp = dim(samples_matrix)[1]\nvar_expl = rep(0, n_samp)\nfor (j in 1:n_samp) {\n  model_matrix = samples_matrix[j, , ]\n  resids = data_matrix - model_matrix\n  var_expl[j] = 1 - var(resids[!mask]) / data_var # 1 - RSS/TSS across covariates\n}\n\n# Summarize global variance explained over posterior samples\nsummary(var_expl)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.9501  0.9509  0.9511  0.9511  0.9512  0.9520"
  },
  {
    "objectID": "posts/MSFAST_Vignette.html#visualizing-multivariate-fpcs",
    "href": "posts/MSFAST_Vignette.html#visualizing-multivariate-fpcs",
    "title": "MSFAST: Bayesian Multivariate, Sparse FPCA Vignette",
    "section": "Visualizing Multivariate FPCs",
    "text": "Visualizing Multivariate FPCs\nWe now visualize the multivariate FPCs according to MSFAST. All estimates are accompanied by the associated equal-tailed 95% credible intervals. For a point of reference, we also include the FPC estimates from mFACEs, though these estimates do not include any uncertainty quantification.\n\n# Format MSFAST estimates\n{\n  MSFAST_FPC = left_join(EF_bounds, EF_ests %&gt;% rename(Func = FPC_Val)) %&gt;%\n    mutate(FuncName = paste0(\"phi[\", substring(FPC_Num, 5), \"](t)\")) %&gt;%\n    mutate(Method = \"MSFAST\", \n           Method = factor(Method, levels = c(\"MSFAST\", \"mFACEs\")), \n           Covar = case_when(Var == 1 ~ \"Length\", \n                             TRUE ~ \"Weight\"))\n}\n\nJoining with `by = join_by(Arg, Var, FPC_Num)`\n\n# Format mFACEs estimates for comparison\n{\n  FACE_FPC = data.frame(phi_tilde)\n  colnames(FACE_FPC) = paste0(\"phi[\", 1:K, \"](t)\")\n  FACE_FPC$Arg = rep(face_fit$argvals.new, 2)\n  FACE_FPC$Covar = rep(c(\"Length\", \"Weight\"), each = length(face_fit$argvals.new))\n  FACE_FPC = FACE_FPC %&gt;%\n    pivot_longer(-c(Arg, Covar), names_to = \"FuncName\", values_to = \"FACE\") %&gt;%\n    mutate(Method = \"mFACEs\", \n           Method = factor(Method, levels = c(\"MSFAST\", \"mFACEs\")))\n}\n\n# Visualize the results\n{\n  MSFAST_FPC %&gt;%\n    ggplot(aes(x = Arg, color = Method, fill = Method)) + \n    geom_ribbon(aes(ymin = LB, ymax = UB), linewidth = 0, alpha = 0.3) +\n    geom_line(aes(y = Func)) + \n    geom_line(data = FACE_FPC, aes(y = FACE)) +\n    facet_grid(Covar~FuncName, labeller = label_parsed) +\n    theme_bw() + \n    labs(x = \"Age (days)\", y = \"Eigenfunction\")\n}\n\n\n\n\n\n\n\n\nWe can also examine the eigenvalue posterior distributions for each of the FPCs estimated above, summarized with corresponding credible intervals in the following table. Again, we use the results from mFACEs for comparison.\n\n# MSFAST eigenvalues from score variances\nMSFAST_EV = map(align$Score, function(x) {\n  ev_sample = apply(x, 2, var)\n  return(data.frame(\n    FPC = paste0(\"Phi_\", 1:K, \"(t)\"),\n    EV = ev_sample\n  ))\n}) %&gt;% list_rbind() %&gt;%\n  group_by(FPC) %&gt;%\n  summarize(`Posterior Mean Lambda` = round(mean(EV), 2), \n            `CI Lower` = round(quantile(EV, probs = c(0.025)), 2), \n            `CI Upper` = round(quantile(EV, probs = c(0.975)), 2))\n\n# mFACEs eigenvalues from model output\nFACE_EV = data.frame(FPC = paste0(\"Phi_\", 1:K, \"(t)\"), \n                     EV = round(face_fit$eigenvalues[1:K], 2)) %&gt;%\n  rename(`mFACEs Lambda` = EV)\n\ninner_join(MSFAST_EV, FACE_EV, by = \"FPC\")\n\n# A tibble: 4 × 5\n  FPC      `Posterior Mean Lambda` `CI Lower` `CI Upper` `mFACEs Lambda`\n  &lt;chr&gt;                      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;\n1 Phi_1(t)                    1.46       1.37       1.55            1.37\n2 Phi_2(t)                    0.24       0.21       0.27            0.35\n3 Phi_3(t)                    0.18       0.16       0.21            0.1 \n4 Phi_4(t)                    0.2        0.14       0.28            0.04\n\n\nAs can be seen above, MSFAST does not agree with mFACEs on the variability explained in the later FPCs, particularly \\(\\boldsymbol{\\Phi}_3(t)\\) and \\(\\boldsymbol{\\Phi}_4(t)\\). Given the tendency of MSFAST to better recover lower signal FPCs, this descrepancy is likely cause for re-ordering of the FPCs during visualization."
  },
  {
    "objectID": "posts/MSFAST_Vignette.html#dynamic-prediction",
    "href": "posts/MSFAST_Vignette.html#dynamic-prediction",
    "title": "MSFAST: Bayesian Multivariate, Sparse FPCA Vignette",
    "section": "Dynamic Prediction",
    "text": "Dynamic Prediction\nWe aim to predict the latent trajectories for the two held-out participants. We iteratively update predictions using these subjects’ data observed up to 150, 300, and 450 days, mimicking the dynamic prediction task. In all cases, we limit trajectory predictions to 500 days, as there is little data to draw from past this point. To form these predictions, we will need to first define relevant constants.\n\n# Predict using data up to 150, 300, and 450 days\nthresholds = 1:3 * 150\n\n# Predict trajectory only up to 500 days\nmax_project = 500\n\n# Object containing posterior samples\nsamples = extract(fit_joint)\n\n# Basis matrix for FPCs when P = 2\nkB = kronecker(diag(P), basis_mat)\n\n# Number of unique observed time points\nM = nrow(basis_mat)\n\nWe can now actually form the trajectory predictions by sampling the subject-specific scores given their available data and the posterior samples of the population-level parameters.\n\ntrajectories = map(thresholds, function(age_thresh) { # Predictions at each threshold\n  sub_traj = map(for_prediction, function(sid) { # Predictions for each participant\n    \n    # Reformat data and standardize\n    subset = content_predict %&gt;%\n      filter(Arg &lt;= age_thresh & id == sid) %&gt;%\n      pivot_longer(-c(id, Arg, S), names_to = \"Metric\", values_to = \"Val\") %&gt;%\n      mutate(Var = case_when(Metric == \"zlen\" ~ 1,\n                             TRUE ~ 2)) %&gt;%\n      left_join(data_list$consts, by = \"Var\") %&gt;%\n      mutate(Val = (Val - mu_Y) / sd_Y)\n    \n    # Structure observations\n    Yi = list(length = subset %&gt;% \n                filter(Metric == \"zlen\") %&gt;%\n                pull(Val),\n              weight = subset %&gt;%\n                filter(Metric == \"zwei\") %&gt;%\n                pull(Val))\n    \n    # Orthogonal spline evaluated at the observed points\n    Bi = list(length = basis_mat[subset %&gt;% filter(Metric == \"zlen\") %&gt;% pull(S), ], \n              weight = basis_mat[subset %&gt;% filter(Metric == \"zwei\") %&gt;% pull(S), ])\n    \n    # Sample the scores conditional on population estimates and available data\n    scores = sample_scores(Yi, Bi, samples) %&gt;%\n      select(-c(Sample)) %&gt;%\n      as.matrix()\n    \n    # Calculate trajectories from sampled scores and population-level samples\n    person_traj = map(1:dim(scores)[1], function(x) {\n      smooths = kB %*% (samples$w_mu[x,] + samples$Psi[x, , ] %*% scores[x, ])\n      \n      return(data.frame(Sample = x, Arg = domain,\n                        zlen = smooths[1:M],\n                        zwei = smooths[(M + 1):(2 * M)]))\n    }) %&gt;% list_rbind() %&gt;%\n      pivot_longer(-c(Arg, Sample),\n                   names_to = \"Metric\",\n                   values_to = \"Traj\")\n    \n    return(person_traj %&gt;% mutate(id = sid))\n  }) %&gt;% list_rbind() %&gt;%\n    filter(Arg &lt;= max_project) %&gt;% # Only project to 500 days\n    mutate(Metric = case_when(Metric == \"zlen\" ~ \"Length\",\n                              TRUE ~ \"Weight\"))\n  \n  return(\n    sub_traj %&gt;% # Summarize trajectories by point-wise mean and credible intervals\n      group_by(id, Metric, Arg) %&gt;%\n      summarize(Est = mean(Traj),\n                UB = quantile(Traj, probs = c(0.975)),\n                LB = quantile(Traj, probs = c(0.025))) %&gt;%\n      mutate(id = paste0(\"Ppt. \", id)) %&gt;%\n      mutate(Data_Max = paste0(\"Age~(days)&lt;=\", age_thresh))\n  )\n}) %&gt;%\n  list_rbind()\n\nTo conclude formatting these predictions, we scale them according to the mean and standard deviation of the observed measures and arrange the thresholds for viewing.\n\ntrajectories = trajectories %&gt;%\n  mutate(Var = case_when(Metric == \"Length\" ~ 1,\n                         TRUE ~ 2)) %&gt;%\n  left_join(data_list$consts, by = \"Var\") %&gt;%\n  mutate(Est = Est * sd_Y + mu_Y, \n         UB = UB * sd_Y + mu_Y, \n         LB = LB * sd_Y + mu_Y) %&gt;%\n  select(-c(Var)) %&gt;% \n  mutate(Data_Max = factor(Data_Max, levels = paste0(\"Age~(days)&lt;=\", thresholds)))\n\nWe next format the raw data for visualization alongside the predicted trajectories.\n\n# Corresponding real data\nreal_data = map(thresholds, function(age_thresh) {\n  return(\n    content_predict %&gt;%\n      filter(Arg &lt;= age_thresh) %&gt;%\n      pivot_longer(-c(id, Arg, S), names_to = \"Metric\", values_to = \"Val\") %&gt;%\n      mutate(\n        id = paste0(\"Ppt. \", id),\n        Metric = case_when(Metric == \"zlen\" ~ \"Length\",\n                           TRUE ~ \"Weight\"),\n        Data_Max = paste0(\"Age~(days)&lt;=\", age_thresh)\n      )\n  )\n}) %&gt;%\n  list_rbind() %&gt;%\n  mutate(Data_Max = factor(Data_Max, levels = paste0(\"Age~(days)&lt;=\", thresholds)))\n\nWe can finally visualize the predictions with the data used to form them, with projected trajectories and their uncertainty shifting with the introduction of additional data. Perhaps most noticeably, the credible interval width decreases substantially as more data is included.\n\ntrajectories %&gt;%\n  ggplot(aes(x = Arg, group = Metric, color = Metric, fill = Metric)) +\n  geom_line(aes(y = Est)) +\n  geom_ribbon(aes(ymin = LB, ymax = UB), alpha = 0.2) +\n  geom_point(data = real_data, aes(y = Val)) +\n  theme_bw() +\n  scale_x_continuous(lim = c(0, 505)) +\n  coord_cartesian(ylim = c(-2.5, 1)) +\n  facet_grid(Data_Max ~ id,\n             labeller = labeller(Data_Max = label_parsed),\n             scales = \"free_y\") +\n  labs(x = \"Age (days)\", y = \"Z-Score\")\n\n\n\n\n\n\n\n\nThis document just visualizes a particular case of applying the “MSFAST” approach to perform fully-Bayesian Functional PCA for sparse, multivariate data. All supporting STAN and R code here is designed to be flexible, such that it may directly be applied to any other similarly structured problem."
  },
  {
    "objectID": "posts/FAST_Vignette.html",
    "href": "posts/FAST_Vignette.html",
    "title": "FAST: Bayesian FPCA Vignette",
    "section": "",
    "text": "source(\"FAST_support/Libs.R\")\nsource(\"FAST_support/Bases.R\")\nsource(\"FAST_support/Convergence.R\")\nsource(\"FAST_support/PostProcess.R\")\nsource(\"FAST_support/FAST_Help.R\")"
  },
  {
    "objectID": "posts/FAST_Vignette.html#read-in-the-nhanes-accelerometry-data",
    "href": "posts/FAST_Vignette.html#read-in-the-nhanes-accelerometry-data",
    "title": "FAST: Bayesian FPCA Vignette",
    "section": "Read in the NHANES Accelerometry Data",
    "text": "Read in the NHANES Accelerometry Data\nFor this brief example analysis, we leverage the objective physical activity data from wrist-worn accelerometry collected as part of NHANES 2011-2014. This dataset is made publicly available as part of “Functional Data Analysis with R” and can be downloaded from the accompanying website. We take a random subsample of 200 individuals subsampled every 10 minutes during the day (144 total measurements) for the sake of time.\n\ndata_path = \"http://www.ciprianstats.org/sites/default/files/nhanes/nhanes_fda_with_r.rds\"\ndownload.file(data_path, \"nhanes.rds\", mode = \"wb\")\naccel_data = readRDS(\"nhanes.rds\")\nfile.remove(\"nhanes.rds\")\n\nset.seed(12345)\nchosen_idxs = sample(1:nrow(accel_data), 200)\naccel_mat = unAsIs(accel_data$MIMS)[chosen_idxs, ]\naccel_df = data.frame(accel_mat)\ncolnames(accel_df) = 1:1440\naccel_df$ID = accel_data$SEQN[chosen_idxs]\naccel_df = accel_df %&gt;%\n  pivot_longer(-c(ID), names_to = \"MoD\", values_to = \"MIMS\") %&gt;%\n  mutate(MoD = as.numeric(MoD), \n         Window = (MoD - 1) %/% 10) %&gt;%\n  group_by(ID, Window) %&gt;%\n  summarize(MIMS = mean(MIMS)) %&gt;%\n  mutate(MoD = Window * 10)"
  },
  {
    "objectID": "posts/FAST_Vignette.html#visualization-of-data-structure",
    "href": "posts/FAST_Vignette.html#visualization-of-data-structure",
    "title": "FAST: Bayesian FPCA Vignette",
    "section": "Visualization of Data Structure",
    "text": "Visualization of Data Structure\nNow that we have the data, we perform quick visualizations to get an idea of the types of patterns present. We first randomly select 5 participant’s MIMS (monitor-independent movement summary) curves.\n\nset.seed(0935867)\nchosen_ids = sample(unique(accel_df$ID), 6)\n\naccel_df %&gt;%\n  filter(ID %in% chosen_ids) %&gt;%\n  mutate(HoD = MoD/60, ID = paste0(\"ID: \", ID)) %&gt;%\n  ggplot(aes(x = HoD, y = MIMS, group = ID)) + \n  geom_line() +\n  facet_wrap(.~ID) + \n  theme_bw() + \n  labs(x = \"Hour of the Day\", y = \"MIMS\")\n\n\n\n\n\n\n\n\nWe can alternatively visualize the entire population using a heatmap structure, where each row is a participant and darker colors correspond to higher activity levels (as in “Functional Data Analysis with R”).\n\naccel_df %&gt;%\n  mutate(ID = factor(ID), \n         HoD = MoD/60) %&gt;%\n  ggplot(aes(x = HoD, y = ID)) + \n  geom_tile(aes(fill = MIMS)) +\n  theme_bw() + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n        panel.background = element_blank()) +\n  scale_fill_gradient(low = \"white\", high = \"black\") + \n  labs(x = \"Hour of the Day\", y = \"Participant\")\n\n\n\n\n\n\n\n\nThis visualization indicates that activity is strongest between the hours of 8AM and 10PM, as would be expected. However, there is substantial heterogeneity both in when individuals start and end their days, as well as the amount of activity they engage in on average throughout the course of the day."
  },
  {
    "objectID": "posts/FAST_Vignette.html#fitting-fast-bayesian-fpca",
    "href": "posts/FAST_Vignette.html#fitting-fast-bayesian-fpca",
    "title": "FAST: Bayesian FPCA Vignette",
    "section": "Fitting FAST Bayesian FPCA",
    "text": "Fitting FAST Bayesian FPCA\nWe first retrieve the matrix representation of the full dataset using the appropriate wrangling. We then define the constants, using spline basis of dimension \\(Q = 25\\) and \\(K = 3\\) FPCs. We provide these values, along with the input data matrix, to the “FAST_datalist()” function, which concludes collating all requisite inputs to the FAST STAN implementation. This includes generating the spline bases for the fixed and random effects functions (b-splines and orthogonal splinets, respectively), along with their associated quadratic penalty matrices. All of these elements are collated into the STAN input list.\n\n# Place data in wide matrix format\nY_mat = accel_df %&gt;% \n  ungroup() %&gt;%\n  select(-c(Window)) %&gt;%\n  pivot_wider(names_from = MoD, values_from = MIMS) %&gt;%\n  select(-c(ID)) %&gt;% as.matrix()\n\n# Define constants\nQ = 25\nK = 3\n\n# Collate list of arguments\nDomain = sort(unique(accel_df$MoD))/60\nScaled_Domain = (Domain - min(Domain))/(max(Domain) - min(Domain))\ndata_list = FAST_datalist(Y_mat, Q, K, Scaled_Domain)\n\nWith all requisite inputs generated, we can finally make the call to RSTAN in order to fit the model, accomplished as follows.\n\nfit_mod = stan(file = \"FAST_support/FAST.stan\",\n               data = data_list, \n               chains = 4, \n               cores = 4, \n               warmup = 3000, \n               iter = 5000)"
  },
  {
    "objectID": "posts/FAST_Vignette.html#evaluating-fit-and-aligning-results",
    "href": "posts/FAST_Vignette.html#evaluating-fit-and-aligning-results",
    "title": "FAST: Bayesian FPCA Vignette",
    "section": "Evaluating Fit and Aligning Results",
    "text": "Evaluating Fit and Aligning Results\nWe first extract and summarize all relevant model parameters, aligning the FPCs and scores according to sign and order.\n\nobjects = FAST_extract(fit_mod, data_list$B_FE, \n                       data_list$B_RE, Domain, data_list)\n\nalign = align_weights(objects$Weights, objects$Score, data_list$B_RE)\nscores_samples = out_Score(align$Score)\n    \nEF_CI = CI_EF(align$EF, Domain)\nEF_est = Psi_SVD_FPC(align$Weights, data_list$B_RE, Domain, K)\nMu_df = out_FE(objects$Mu, Domain) %&gt;%\n  group_by(Arg) %&gt;%\n  summarize(Est = mean(Mu), \n            LB = quantile(Mu, probs = c(0.025)), \n            UB = quantile(Mu, probs = c(0.975)))\n\nThe next step is assessment of model convergence using Gelman-Rubin RHat statistics. Principal component sign and ordering are aligned prior to calculating these sampling diagnostics. These measures are calculated using the “RHat_FAST()” function as follows. This function calculates the median and max RHat observed for each FPC/covariate grouping within parameter families. The results below indicate that all parameters have converged according to the heuristic RHat &lt; 1.05 threshold.\n\nrhats = RHat_FAST(fit_mod, data_list, align$EF[[1]])\n\n# FPCs, grouped by FPC/functional component\nrhats$Func\n\n# A tibble: 4 × 3\n  Function Med_RHat Max_RHat\n  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;\n1 FPC 1        1.02     1.02\n2 FPC 2        1.02     1.02\n3 FPC 3        1.00     1.00\n4 Mu           1.01     1.01\n\n# Scores, grouped by FPC\nrhats$Score\n\n# A tibble: 3 × 3\n  FPC_Num Med_RHat Max_RHat\n  &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n1 FPC 1       1.01     1.03\n2 FPC 2       1.01     1.02\n3 FPC 3       1.00     1.01\n\n# Smoothing parameters, grouped by functional component\nrhats$Smoothing_Params\n\n  Function      RHat\n1    FPC 1 1.0002062\n2    FPC 2 0.9997524\n3    FPC 3 0.9997878\n4       Mu 0.9997878\n\n# Variance components (eigenvalues and noise variance)\nrhats$Variances\n\n   Element     RHat\n1 Lambda_1 1.007618\n2 Lambda_2 1.012016\n3 Lambda_3 1.000078\n4   Sigma2 1.000626\n\n\nTo evaluate the adequacy of \\(K = 3\\) principal components, we evaluate the posterior distribution of variability explained. Results indicate that \\(K = 3\\) principal components explains \\(\\approx 80\\)% of the variability in the observed data.\n\n# True data in sparse matrix form\ndata_var = var(as.vector(Y_mat))\n\n# Modeled smooths in sparse matrix of dim. samples x ppts x obs\nsamples_matrix = Smooth_Raw(objects$Mu, align$EF, align$Score, data_list)\nn_samp = dim(samples_matrix)[1]\nvar_expl = rep(0, n_samp)\nfor (j in 1:n_samp) {\n  model_matrix = samples_matrix[j, , ]\n  resids = Y_mat - model_matrix\n  var_expl[j] = 1 - var(as.vector(resids)) / data_var # 1 - RSS/TSS across covariates\n}\n\n# Summarize global variance explained over posterior samples\nsummary(var_expl)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7803  0.7811  0.7813  0.7813  0.7815  0.7822"
  },
  {
    "objectID": "posts/FAST_Vignette.html#visualizing-principal-components",
    "href": "posts/FAST_Vignette.html#visualizing-principal-components",
    "title": "FAST: Bayesian FPCA Vignette",
    "section": "Visualizing Principal Components",
    "text": "Visualizing Principal Components\nWith FAST fit, we can now visualize the extracted and aligned model components: fixed effects function \\(\\mu(t)\\), eigenfunctions \\(\\phi_k(t)\\), and eigenvalues \\(\\lambda_k\\). We first visualize the fixed effects mean \\(\\mu(t)\\), displaying the posterior mean estimate, equal-tail 95% credible interval, and 3 posterior samples.\n\nchosen_samples = sample(length(objects$Mu), 3)\nfunc_samples = map(chosen_samples, function(idx){\n  out_df = data.frame(Mu = objects$Mu[[idx]],\n                      Arg = Domain, Sample = idx)\n  return(out_df)\n}) %&gt;% list_rbind()\n\nMu_df %&gt;%\n  ggplot(aes(x = Arg)) + \n  geom_line(aes(y = Est)) + \n  geom_ribbon(aes(ymin = LB, ymax = UB), alpha = 0.1) + \n  geom_line(data = func_samples, aes(y = Mu, group = Sample), color = \"red\", alpha = 0.5) +\n  theme_bw() + \n  labs(x = \"Hour of the Day\", y = parse(text = \"mu(t)~Estimate\"))\n\n\n\n\n\n\n\n\nWe can similarly visualize the samples of eigenfunctions \\(\\phi_k(t)\\), again including the estimate, equal-tail 95% credible interval, and 3 posterior samples in red.\n\nfunc_sample = map(chosen_samples, function(idx){\n  out_df = FPC_df(align$EF[[idx]], Domain) %&gt;%\n    mutate(Sample = idx, \n           EFLab = paste0(\"phi[\", substring(FPC_Num, 4), \"](t)\"))\n  return(out_df)\n}) %&gt;% list_rbind()\n\nleft_join(EF_est, EF_CI) %&gt;%\n  mutate(EFLab = paste0(\"phi[\", substring(FPC_Num, 4), \"](t)\")) %&gt;%\n  ggplot(aes(x = Arg)) + \n  geom_line(aes(y = FPC_Val)) +\n  geom_ribbon(aes(ymin = LB, ymax = UB), alpha = 0.1) + \n  geom_line(data = func_sample, aes(y = FPC_Val, group = Sample), color = \"red\", alpha = 0.5) +\n  facet_wrap(.~EFLab, labeller = label_parsed) + \n  theme_bw() + \n  labs(x = \"Hour of the Day\", y = \"Eigenfunction Estimate\")\n\n\n\n\n\n\n\n\nWe can also evaluate the variability decomposition by plotting the estimated eigenvalues \\(\\lambda_k\\) sequentially with their equal-tail 95% credible intervals.\n\nlabs = paste0(\"lambda[\", 1:K, \"]\")\nnames(labs) = paste0(\"FPC \", 1:K)\n\nmap(1:length(align$Score), function(x){\n  eigenvals = apply(align$Score[[x]], 2, var)\n  return(data.frame(FPC = paste0(\"FPC \", 1:K), \n                    EVal = eigenvals))\n}) %&gt;% list_rbind() %&gt;%\n  group_by(FPC) %&gt;%\n  summarize(Est = mean(EVal),\n            LB = quantile(EVal, probs = c(0.025)), \n            UB = quantile(EVal, probs = c(0.975))) %&gt;%\n  ggplot(aes(x = FPC, y = Est, group = \"\")) +\n  geom_point() + \n  geom_line() + \n  geom_errorbar(aes(ymin = LB, ymax = UB), width = 0.5) + \n  scale_x_discrete(labels = parse(text = labs)) + \n  labs(y = \"Eigenvalue\") + \n  theme_bw() + \n  theme(axis.title.x = element_blank())\n\n\n\n\n\n\n\n\nThis document just visualizes a particular case of applying the “FAST” approach to perform fully-Bayesian Functional PCA. All supporting STAN and R code here is designed to be flexible, such that it may directly be applied to any other similarly structured problem."
  },
  {
    "objectID": "posts/Visualizing.html",
    "href": "posts/Visualizing.html",
    "title": "Data Visualization Principles",
    "section": "",
    "text": "Cardiovascular-Kidney-Metabolic (CKM) Syndrome Stage\nTroponin T/I\nMinutes of Moderate-to-Vigorous Physical Activity (MVPA)\n\n\nActigraph GT3X [1]"
  },
  {
    "objectID": "posts/Visualizing.html#nhanes-2003-2006",
    "href": "posts/Visualizing.html#nhanes-2003-2006",
    "title": "Data Visualization Principles",
    "section": "",
    "text": "Cardiovascular-Kidney-Metabolic (CKM) Syndrome Stage\nTroponin T/I\nMinutes of Moderate-to-Vigorous Physical Activity (MVPA)\n\n\nActigraph GT3X [1]"
  },
  {
    "objectID": "posts/Visualizing.html#table-1",
    "href": "posts/Visualizing.html#table-1",
    "title": "Data Visualization Principles",
    "section": "“Table 1”",
    "text": "“Table 1”\n\nInitial PassImprovement 1A New PerspectivePrinciples\n\n\nWe use the table1 R package to make a simple, standard table 1:\n\n\nCKMStage 0(N=487)Stage 1(N=1179)Stage 2(N=3963)Stage 3(N=772)Stage 4(N=845)Age (yrs)  Mean (SD)34.1 (12.4)38.9 (14.1)48.5 (15.1)76.7 (7.44)68.8 (12.8)  Median [Min, Max]32.0 [20.0, 85.0]36.0 [20.0, 85.0]48.0 [20.0, 85.0]78.0 [32.0, 85.0]70.0 [26.0, 85.0]Female67.56%55.47%48.25%43.78%42.72%MVPA (min/day)  Mean (SD)27.0 (22.6)21.7 (21.1)18.2 (19.9)6.45 (10.3)7.39 (12.1)  Median [Min, Max]21.9 [0, 187]15.7 [0, 181]11.9 [0, 175]2.43 [0, 83.7]2.43 [0, 107]Diabetes0.00%0.00%12.06%33.42%35.15%Hypertension0.00%0.00%72.55%93.78%94.91%\n\n\n\n\nWe can increase the information density by removing unnecessary information:\n\n\nCKMStage 0(N=487)Stage 1(N=1179)Stage 2(N=3963)Stage 3(N=772)Stage 4(N=845)MVPA (min/day)27.0 (25.0, 29.0)21.7 (20.5, 22.9)18.2 (17.6, 18.8)6.4 (5.7, 7.2)7.4 (6.6, 8.2)Age (yrs)34.1 (33.0, 35.2)38.9 (38.1, 39.7)48.5 (48.1, 49.0)76.7 (76.1, 77.2)68.8 (68.0, 69.7)Female68%55%48%44%43%Diabetes0%0%12%33%35%Hypertension0%0%73%94%95%\n\n\n\n\nIt is easier to perform comparisons vertically, rather than horizontally:\n\n\nCKM StageNMVPAAgeFemaleDiabetesHypertensionStage 048727.0(26.9, 27.1)34[24, 40]68%0%0%Stage 11,17921.7(21.7, 21.7)39[28, 47]55%0%0%Stage 23,96318.2(18.2, 18.2)49[37, 61]48%12%73%Stage 37726.4(6.4, 6.4)77[72, 83]44%33%94%Stage 48457.4(7.4, 7.4)69[61, 80]43%35%95%\n\n\n\n\n\nGrouping by proximity (Gestalt Principle)\nData-ink-ratio (Tufte)\nEncourage comparison (Tufte)\nVertical contrasts are easier (Broman)"
  },
  {
    "objectID": "posts/Visualizing.html#mvpa-by-ckm-status",
    "href": "posts/Visualizing.html#mvpa-by-ckm-status",
    "title": "Data Visualization Principles",
    "section": "MVPA by CKM Status",
    "text": "MVPA by CKM Status\n\nInitial PassImprovement 1Improvement 2Principles\n\n\nWe first leverage a standard bar chart with uncertainty bounds to first visualize the mean minutes of MVPA by CKM status:\n\n\n\n\n\n\n\n\n\n\n\nWe can show a subsample of the actual data, and remove the bar portions which provide no additional information:\n\n\n\n\n\n\n\n\n\n\n\nWe can invite comparison by linking the points together with a line, and scale the right-skewed data with a log transformation:\n\n\n\n\n\n\n\n\n\n\n\n\nShow the data (Tufte)\nData-ink-ratio (Tufte)\nData transforms (Broman)\nGrouping by continuity (Gestalt Principal)"
  },
  {
    "objectID": "posts/Visualizing.html#mvpa-by-ckm-cont.",
    "href": "posts/Visualizing.html#mvpa-by-ckm-cont.",
    "title": "Data Visualization Principles",
    "section": "MVPA by CKM Cont.",
    "text": "MVPA by CKM Cont.\n\nInitial PassImprovement 1Improvement 2Principles\n\n\nHistograms are a common method for visualizing distributions such as that of MVPA within each CKM status:\n\n\n\n\n\n\n\n\n\n\n\nWe cannot really compare the histograms due to the information of interest being along the x-axis and the differing summative frequencies. We can instead vertically stack density plots:\n\n\n\n\n\n\n\n\n\n\n\nThe vertical stack of density plots is still not optimal for comparison, so we can overlay them on one plot with appropriate coloration.\n\n\n\n\n\n\n\n\n\n\n\n\nData density (Tufte)\nSame scales (Broman)\nData transforms (Broman)\nRapid vs deliberate thinking (Kahneman)"
  },
  {
    "objectID": "posts/Visualizing.html#aha-activity-guideline",
    "href": "posts/Visualizing.html#aha-activity-guideline",
    "title": "Data Visualization Principles",
    "section": "AHA Activity Guideline",
    "text": "AHA Activity Guideline\n\nInitial PassImprovement 1Improvement 2Principles\n\n\nTo visualize the CKM status compositions within the subpopulations meeting and not meeting the AHA MVPA guideline, a first thought might be to use pie charts. This makes some sense, as we wish to display proportions within each group:\n\n\n\n\n\n\n\n\n\n\n\nPie charts are notoriously difficult to accurately read, so we can transition to a stacked bar chart:\n\n\n\n\n\n\n\n\n\n\n\nWhile the stacked bar chart is an improvement, the relevant lengths are not juxtaposed to perform the comparison of interest. We can arrange them instead using a standard bar chart:\n\n\n\n\n\n\n\n\n\n\n\n\nEasy comparison (Broman, Tufte, Simkin and Hastie)\nGrouping by proximity (Gestalt Principle)"
  },
  {
    "objectID": "posts/Visualizing.html#mvpa-vs-troponin-t",
    "href": "posts/Visualizing.html#mvpa-vs-troponin-t",
    "title": "Data Visualization Principles",
    "section": "MVPA vs Troponin T",
    "text": "MVPA vs Troponin T\n\nInitial PassImprovementA New PerspectivePrinciples\n\n\nWe first model the expected probability of elevated troponin (by sex-specific cutpoint), adjusting for the known confounder of age.\n\n\n\n\n\n\n\n\n\n\n\nWisualizing expected probability of exceeding this threshold, particularly just using a model, obfuscates the data. Instead we can simply plot troponin vs activity and corresponding smooths, stratified by age:\n\n\n\n\n\n\n\n\n\n\n\nWe want to both understand the marginal distributions of activity and troponin by age group, as well as the association between these two around the AHA recommendation. For these purposes, and to ease comparison, we combine into a single plot with marginal visualizations and a magnification plot:\n\n\n\n\n\n\n\n\n\n\n\n\nLet the data talk (Tufte, Broman)\nRapid AND deliberate elements (Kahneman)\nVisualize multiple scales (Tufte)\nGrouping by enclosure (Gestalt Principle)"
  },
  {
    "objectID": "posts/Visualizing.html#further-reading",
    "href": "posts/Visualizing.html#further-reading",
    "title": "Data Visualization Principles",
    "section": "Further Reading",
    "text": "Further Reading\n\n\n[1] Thornton C, Kolehmainen N, Nazarpour K. Using unsupervised machine learning to quantify physical activity from accelerometry in a diverse and rapidly changing population. PLOS Digital Health 2023;2:e0000220. https://doi.org/10.1371/journal.pdig.0000220.\n\n\n[2] Kahneman D. Attention and effort. Prentice-Hall; 1973.\n\n\n[3] Tufte ER. The visual display of quantitative information. Second. Cheshire, Connecticut: Graphics Press; 2001.\n\n\n[4] What are the Gestalt Principles? — updated 2024. The Interaction Design Foundation n.d.\n\n\n[5] Simkin D, Hastie R. An Information-Processing Analysis of Graph Perception. Journal of the American Statistical Association 1987;82:454–65. https://doi.org/10.1080/01621459.1987.10478448.\n\n\n[6] Broman K. Advanced data analysis 2020.\n\n\n[7] Padilla LM, Creem-Regehr SH, Hegarty M, Stefanucci JK. Decision making with visualizations: A cognitive framework across disciplines. Cognitive Research: Principles and Implications 2018;3:29. https://doi.org/10.1186/s41235-018-0120-9."
  },
  {
    "objectID": "resources/publications/pre_print/sartini_MSFAST_2025.html",
    "href": "resources/publications/pre_print/sartini_MSFAST_2025.html",
    "title": "Bayesian Multivariate Sparse Functional PCA",
    "section": "",
    "text": "Citation (APA 7)\n\nSartini, J., Zeger, S., & Crainiceanu, C. (2025). Bayesian Multivariate Sparse Functional PCA (No. arXiv:2509.03512). arXiv. https://doi.org/10.48550/arXiv.2509.03512\n\nAbstract\nFunctional Principal Components Analysis (FPCA) provides a parsimonious, semi-parametric model for multivariate, sparsely-observed functional data. Frequentist FPCA approaches estimate principal components (PCs) from the data, then condition on these estimates in subsequent analyses. As an alternative, we propose a fully Bayesian inferential framework for multivariate, sparse functional data (MSFAST) which explicitly models the PCs and incorporates their uncertainty. MSFAST builds upon the FAST approach to FPCA for univariate, densely-observed functional data. Like FAST, MSFAST represents PCs using orthonormal splines, samples the orthonormal spline coefficients using parameter expansion, and enforces eigenvalue ordering during model fit. MSFAST extends FAST to multivariate, sparsely-observed data by (1) standardizing each functional covariate to mitigate poor posterior conditioning due to disparate scales; (2) using a better-suited orthogonal spline basis; (3) parallelizing likelihood calculations over covariates; (4) updating parameterizations and priors for computational stability; (5) using a Procrustes-based posterior alignment procedure; and (6) providing efficient prediction routines. We evaluated MSFAST alongside existing implementations using simulations. MSFAST produces uniquely valid inferences and accurate estimates, particularly for smaller signals. MSFAST is motivated by and applied to a study of child growth, with an accompanying vignette illustrating the implementation step-by-step."
  },
  {
    "objectID": "resources/publications/in_print/michelmata_evolution_2024.html",
    "href": "resources/publications/in_print/michelmata_evolution_2024.html",
    "title": "The evolution of private reputations in information-abundant landscapes",
    "section": "",
    "text": "Michel-Mata, S., Kawakatsu, M., Sartini, J. et al. The evolution of private reputations in information-abundant landscapes. Nature 634, 883–889 (2024). https://doi.org/10.1038/s41586-024-07977-x"
  },
  {
    "objectID": "resources/publications/in_print/michelmata_evolution_2024.html#citation-apa",
    "href": "resources/publications/in_print/michelmata_evolution_2024.html#citation-apa",
    "title": "The evolution of private reputations in information-abundant landscapes",
    "section": "",
    "text": "Michel-Mata, S., Kawakatsu, M., Sartini, J. et al. The evolution of private reputations in information-abundant landscapes. Nature 634, 883–889 (2024). https://doi.org/10.1038/s41586-024-07977-x"
  },
  {
    "objectID": "resources/publications/in_print/michelmata_evolution_2024.html#abstract",
    "href": "resources/publications/in_print/michelmata_evolution_2024.html#abstract",
    "title": "The evolution of private reputations in information-abundant landscapes",
    "section": "Abstract",
    "text": "Abstract\nReputations are critical to human societies, as individuals are treated differently based on their social standing1,2. For instance, those who garner a good reputation by helping others are more likely to be rewarded by third parties3,4,5. Achieving widespread cooperation in this way requires that reputations accurately reflect behaviour6 and that individuals agree about each other’s standings7. With few exceptions8,9,10, theoretical work has assumed that information is limited, which hinders consensus7,11 unless there are mechanisms to enforce agreement, such as empathy12, gossip13,14,15 or public institutions16. Such mechanisms face challenges in a world where empathy, effective communication and institutional trust are compromised17,18,19. However, information about others is now abundant and readily available, particularly through social media. Here we demonstrate that assigning private reputations by aggregating several observations of an individual can accurately capture behaviour, foster emergent agreement without enforcement mechanisms and maintain cooperation, provided individuals exhibit some tolerance for bad actions. This finding holds for both first- and second-order norms of judgement and is robust even when norms vary within a population. When the aggregation rule itself can evolve, selection indeed favours the use of several observations and tolerant judgements. Nonetheless, even when information is freely accessible, individuals do not typically evolve to use all of it. This method of assessing reputations—‘look twice, forgive once’, in a nutshell—is simple enough to have arisen early in human culture and powerful enough to persist as a fundamental component of social heuristics."
  },
  {
    "objectID": "resources/publications/in_print/sartini_GCI_2024.html",
    "href": "resources/publications/in_print/sartini_GCI_2024.html",
    "title": "Glucose Color Index: Development and Validation of a Novel Measure of the Shape of Glycemic Variability",
    "section": "",
    "text": "Sartini J, Fang M, Rooney MR, Selvin E, Coresh J, Zeger S. Glucose Color Index: Development and Validation of a Novel Measure of the Shape of Glycemic Variability. Journal of Diabetes Science and Technology. 2024;0(0). doi:10.1177/19322968241245654"
  },
  {
    "objectID": "resources/publications/in_print/sartini_GCI_2024.html#citation-apa-7",
    "href": "resources/publications/in_print/sartini_GCI_2024.html#citation-apa-7",
    "title": "Glucose Color Index: Development and Validation of a Novel Measure of the Shape of Glycemic Variability",
    "section": "",
    "text": "Sartini J, Fang M, Rooney MR, Selvin E, Coresh J, Zeger S. Glucose Color Index: Development and Validation of a Novel Measure of the Shape of Glycemic Variability. Journal of Diabetes Science and Technology. 2024;0(0). doi:10.1177/19322968241245654"
  },
  {
    "objectID": "resources/publications/in_print/sartini_GCI_2024.html#abstract",
    "href": "resources/publications/in_print/sartini_GCI_2024.html#abstract",
    "title": "Glucose Color Index: Development and Validation of a Novel Measure of the Shape of Glycemic Variability",
    "section": "Abstract",
    "text": "Abstract\nBackground: Standard continuous glucose monitoring (CGM) metrics: mean glucose, standard deviation, coefficient of variation, and time in range, fail to capture the shape of variability in the CGM time series. This information could facilitate improved diabetes management. Methods: We analyzed CGM data from 141 adults with type 2 diabetes in the Hyperglycemic Profiles in Obstructive Sleep Apnea (HYPNOS) trial. Participants in HYPNOS wore CGM sensors for up to two weeks at two time points, three months apart. We calculated the log-periodogram for each time period, summarizing using disjoint linear models. These summaries were combined into a single value, termed the Glucose Color Index (GCI), using canonical correlation analysis. We compared the between-wear correlation of GCI with those of standard CGM metrics and assessed associations between GCI and diabetes comorbidities in 398 older adults with type 2 diabetes from the Atherosclerosis Risk in Communities (ARIC) study. Results: The GCI achieved a test-retest correlation of R = .75. Adjusting for standard CGM metrics, the GCI test-retest correlation was R = .55. Glucose Color Index was significantly associated (p &lt; .05) with impaired physical functioning, frailty/pre-frailty, cardiovascular disease, chronic kidney disease, and dementia/mild cognitive impairment after adjustment for confounders. Conclusion: We developed and validated the GCI, a novel CGM metric that captures the shape of glucose variability using the periodogram signal decomposition. Glucose Color Index was reliable within participants over a three-month period and associated with diabetes comorbidities. The GCI suggests a promising avenue toward the development of CGM metrics which more fully incorporate time series information."
  },
  {
    "objectID": "resources/publications/in_print/sartini_PACKM_2025.html",
    "href": "resources/publications/in_print/sartini_PACKM_2025.html",
    "title": "Light physical activity and all-cause mortality in US adults across Cardiovascular-Kidney-Metabolic Syndrome Stages",
    "section": "",
    "text": "Sartini, J., Rooney, M. R., Schrack, J. A., McEvoy, J. W., Ndumele, C. E., Zeger, S., Selvin, E., & Fang, M. (2026). Light Physical Activity and All‐Cause Mortality in US Adults Across Cardiovascular‐Kidney‐Metabolic Syndrome Stages. Journal of the American Heart Association, 0(0), e046271. https://doi.org/10.1161/JAHA.125.046271"
  },
  {
    "objectID": "resources/publications/in_print/sartini_PACKM_2025.html#citation-apa-7",
    "href": "resources/publications/in_print/sartini_PACKM_2025.html#citation-apa-7",
    "title": "Light physical activity and all-cause mortality in US adults across Cardiovascular-Kidney-Metabolic Syndrome Stages",
    "section": "",
    "text": "Sartini, J., Rooney, M. R., Schrack, J. A., McEvoy, J. W., Ndumele, C. E., Zeger, S., Selvin, E., & Fang, M. (2026). Light Physical Activity and All‐Cause Mortality in US Adults Across Cardiovascular‐Kidney‐Metabolic Syndrome Stages. Journal of the American Heart Association, 0(0), e046271. https://doi.org/10.1161/JAHA.125.046271"
  },
  {
    "objectID": "resources/publications/in_print/sartini_PACKM_2025.html#news-coverage",
    "href": "resources/publications/in_print/sartini_PACKM_2025.html#news-coverage",
    "title": "Light physical activity and all-cause mortality in US adults across Cardiovascular-Kidney-Metabolic Syndrome Stages",
    "section": "News Coverage",
    "text": "News Coverage\n\nAmerican Heart Association Release\nU.S. News\nPowers Health\nEveryday Health"
  },
  {
    "objectID": "resources/publications/in_print/selvin_variability_2023.html",
    "href": "resources/publications/in_print/selvin_variability_2023.html",
    "title": "Within-person and between-sensor variability in continuous glucose monitoring metrics",
    "section": "",
    "text": "Selvin, E., Wang, D., Rooney, M. R., Fang, M., Echouffo-Tcheugui, J. B., Zeger, S., Sartini, J., Tang, O., Coresh, J., Nisha Aurora, R., & Punjabi, N. M. (2023). Within-Person and Between-Sensor Variability in Continuous Glucose Monitoring Metrics. Clinical chemistry, 69(2), 180–188. https://doi.org/10.1093/clinchem/hvac192"
  },
  {
    "objectID": "resources/publications/in_print/selvin_variability_2023.html#citation-apa-7",
    "href": "resources/publications/in_print/selvin_variability_2023.html#citation-apa-7",
    "title": "Within-person and between-sensor variability in continuous glucose monitoring metrics",
    "section": "",
    "text": "Selvin, E., Wang, D., Rooney, M. R., Fang, M., Echouffo-Tcheugui, J. B., Zeger, S., Sartini, J., Tang, O., Coresh, J., Nisha Aurora, R., & Punjabi, N. M. (2023). Within-Person and Between-Sensor Variability in Continuous Glucose Monitoring Metrics. Clinical chemistry, 69(2), 180–188. https://doi.org/10.1093/clinchem/hvac192"
  },
  {
    "objectID": "resources/publications/in_print/selvin_variability_2023.html#abstract",
    "href": "resources/publications/in_print/selvin_variability_2023.html#abstract",
    "title": "Within-person and between-sensor variability in continuous glucose monitoring metrics",
    "section": "Abstract",
    "text": "Abstract\nBackground: The within-person and between-sensor variability of metrics from different interstitial continuous glucose monitoring (CGM) sensors in adults with type 2 diabetes not taking insulin is unclear. Methods: Secondary analysis of data from 172 participants from the HYPNOS randomized clinical trial. Participants simultaneously wore Dexcom G4 and Abbott Libre Pro CGM sensors for up to 2-weeks at baseline and, again, at the 3-month follow-up visit. Results: At baseline (up to 2-weeks of CGM), mean glucose for both the Abbot and Dexcom sensors was approximately 150 mg/dl and time-in-range (70-180 mg/dL) was just below 80%. When comparing the same sensor at two different time points (two 2-week wear periods, 3 months apart), the within-person variability (CVw) in mean glucose was 17.4% (Abbott) and 14.2% (Dexcom). CVw for percent time-in-range: 20.1% (Abbott) and 18.6% (Dexcom). At baseline, the Pearson’s correlation of mean glucose from the two sensors worn simultaneously was r=0.86, root mean squared error (RMSE), 13 mg/dL; for time-in-range, r=0.88, RMSE 8%-points. Conclusions: Substantial variation was observed within sensors over time and across two different sensors worn simultaneously on the same individuals. Clinicians should be aware of this variability when using CGM technology to make clinical decisions."
  },
  {
    "objectID": "talks/Job_Talk.html#agenda",
    "href": "talks/Job_Talk.html#agenda",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Agenda",
    "text": "Agenda\n\n\nModeling Continuous Glucose Monitor (CGM) Data\nA Bayesian Functional Model for CGM Data\nModel Performance\nModel Inference on CGM\nExtending our approach\n\n\n\nPoints to hit:\n\nIntroduce the scientific problem(s) we hope to address\nModeling approach to leverage this data\nHow does the approach do in objective evaluation\nApplying the approach to our data\nCan the approach be generalized more broadly?\n\nTransition: With that said, let’s get started"
  },
  {
    "objectID": "talks/Job_Talk.html#public-health-perspective-diabetes",
    "href": "talks/Job_Talk.html#public-health-perspective-diabetes",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Public Health Perspective: Diabetes",
    "text": "Public Health Perspective: Diabetes\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstimates collated by the CDC using data from the National Heath and Nutrition Examination Survey.\n\n\n\n\n13.5% (40.1 million) in 20231\n$412.9 billion in expenditures in 20222\nIncreasing complications: kidney failure, stroke, heart failure\n\n\n\n\nLikely not new information to many in this room\nPoints to hit:\n\nPrevalence generally increasing since 2001\nMore diabetes = more costs/negative outcomes\n\nTransition: None\n\n\n\n(Baumblatt et al., 2024)(Parker et al., 2024)"
  },
  {
    "objectID": "talks/Job_Talk.html#continuous-glucose-monitors-cgm",
    "href": "talks/Job_Talk.html#continuous-glucose-monitors-cgm",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Continuous Glucose Monitors (CGM)",
    "text": "Continuous Glucose Monitors (CGM)\n\n\n\n\n\nExample CGM device and readout from NIDDK.\n\n\n\n\nEstimates blood glucose every 1-15 minutes, \\(\\leq 15\\) days\nRecommended for diabetes management1\nSystem response to food, exercise, etc.\n\n\n\n\nPoints to hit:\n\nIntroduced by medical device companies to help those with diabetes maintain control of their glucose\nSmall wearable devices that are placed on the back of the upper arm, filament inserted into the skin, measures glucose there, uses it to estimate blood glucose\nSampling rate depends on device, wear period dictated by infection risk\nRecommended for management by ADA for any populations with diabetes, particularly those at risk of dangerous low blood glucose\n\nType 1, Type 2 using glucose lowering medications\n\nFrom a research perspective, we can use these devices to observe glucose system response to stimuli, including lifestyle interventions\n\nTransition: None\n\n\n\n(American Diabetes Association Professional Practice Committee for Diabetes*, 2025)"
  },
  {
    "objectID": "talks/Job_Talk.html#dash4d-cgm",
    "href": "talks/Job_Talk.html#dash4d-cgm",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "DASH4D-CGM",
    "text": "DASH4D-CGM\n\n\nDietary Approaches to stop Hypertension for Diabetes\n\n\n\n\n\\(N = 89\\) adults with type 2 diabetes\nRandomized, crossover feeding study1\n\nMeals from study center\nDASH4D vs. Comparison\nWore blinded CGM\n\n\n\n\n\nDASH4D reduces mean glucose, increases time in normal range2\nHow does DASH4D affect postprandial glucose response (PPGR)?\n\n\n\n\n\n\n\nExample DASH4D-compliant meal from the study website.\n\n\n\n\nPoints to hit:\n\nBrings us to the DASH4D study I have had the great pleasure of being a part of.\nDietary approaches to stop hypertension for diabetes, dash-style diet adapted to those with diabetes (adjusted micro/macronutrients to control glucose load). Goal was to assess impact of this diet on measures of glycemic control.\nStudy details, DON’T DO TOO MUCH\nBased on the study data, we already know that DASH4D reduces mean CGM glucose and increases Time in normal range\nWe are interested instead in more granular postprandial glucose response (glucose after meals). This should be the main mechanism through which the diet works, but that has not been quantified nor shown.\n\nTransition: But how do we get postprandial data from CGM?\n\n\n\n(Pilla et al., 2025)(Fang et al., 2025)"
  },
  {
    "objectID": "talks/Job_Talk.html#cgm-data",
    "href": "talks/Job_Talk.html#cgm-data",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "CGM Data",
    "text": "CGM Data\n\n\n\n\n\n\n\n\n\n\n\n\\(65\\) participants\n\n\n\n\n\n\n\n\\(65\\) participants\n\n\n\\(768\\) PPGR curves\n\n\\(3\\)-\\(15\\) per subject\n\n\n\n\nPoints to hit:\n\nRaw data: 3 days from a single participant\nClose collaboration produced validated postprandial responses for 65 participants\nMark them with dashed vertical, extract data around those points\n\n4 hours after: postprandial response\n1 hour before: any changes in fasting, or resting glucose\n\nCan collect all such curves for each participant, highlighting those marked above (mention number)\n\nTransition: How does existing literature model this data?"
  },
  {
    "objectID": "talks/Job_Talk.html#summarizing-ppgr",
    "href": "talks/Job_Talk.html#summarizing-ppgr",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Summarizing PPGR",
    "text": "Summarizing PPGR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMixed effects model at each time \\(t\\)\n\n\nPoints to hit:\n\nExisting analyses pick a single time point (draw vertical line and collect intersections with the curves)\nTo see the structure of the data, we have marked the person-specific means for each diet in blue, contrasting with the overall pooled means for each diet in red.\nShows the hierarchical structure: subject means deviate from the population mean and raw observations are distributed around the subject means\nUsing just this data, we can directly applied mixed effects modeling\n\nTransition: None"
  },
  {
    "objectID": "talks/Job_Talk.html#linear-mixed-models",
    "href": "talks/Job_Talk.html#linear-mixed-models",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Linear Mixed Models",
    "text": "Linear Mixed Models\n\n\\[PPGR^{(60)}_{ij} = \\beta_0^{(60)} + DASH4D_{ij} \\times \\boxed{\\boldsymbol{\\beta_1^{(60)}}} + (\\ldots) + U_i^{(60)} + \\epsilon_{ij}^{(60)}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoints to hit:\n\nSo we can fit those models - go through the model definition (don’t mention superscripts until the end)\nCovariates accounted for: age, sex, BMI, time of day\nWe plot the beta1 estimate here at 1 hour\n\nTransition: None"
  },
  {
    "objectID": "talks/Job_Talk.html#linear-mixed-models-1",
    "href": "talks/Job_Talk.html#linear-mixed-models-1",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Linear Mixed Models",
    "text": "Linear Mixed Models\n\n\\[PPGR^{(120)}_{ij} = \\beta_0^{(120)} + DASH4D_{ij} \\times \\boxed{\\boldsymbol{\\beta_1^{(120)}}} + (\\ldots) + U_i^{(120)} + \\epsilon_{ij}^{(120)}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoints to hit:\n\nCan do the same thing at the 2 hour mark\nNote change in superscript, indicates different set of data is used\nEstimates are similar"
  },
  {
    "objectID": "talks/Job_Talk.html#linear-mixed-models-2",
    "href": "talks/Job_Talk.html#linear-mixed-models-2",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Linear Mixed Models",
    "text": "Linear Mixed Models\n\n\\[PPGR^{(t)}_{ij} = \\beta_0^{(t)} + DASH4D_{ij} \\times \\boxed{\\boldsymbol{\\beta_1^{(t)}}} + (\\ldots) + U_i^{(t)} + \\epsilon_{ij}^{(t)}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoints to hit:\n\nNothing stopping us from fitting at all time points independently\nThis treats the data as independent, which is not necessarily true\nFor those familiar with longitudinal and multilevel modeling, accounting for correlation time point to time point is necessary to have valid inferences on estimates\n\nEven if estimates themselves don’t change much (OLS gives unbiased estimates when there is not much missing data)\n\n\nTransition: None"
  },
  {
    "objectID": "talks/Job_Talk.html#agenda-1",
    "href": "talks/Job_Talk.html#agenda-1",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Agenda",
    "text": "Agenda\n\n\nModeling Continuous Glucose Monitor (CGM) Data\nA Bayesian Functional Model for CGM Data\nModel Performance\nModel Inference on CGM\nExtending our approach\n\n\n\nTransition: This brings us to joint modeling of the data accounting for the correlation structure, where we adapt a functional perspective and Bayesian fitting framework"
  },
  {
    "objectID": "talks/Job_Talk.html#moving-to-a-functional-model",
    "href": "talks/Job_Talk.html#moving-to-a-functional-model",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Moving to a Functional Model",
    "text": "Moving to a Functional Model\n\nSources of Structure:\n\n\n\n\nTemporality\n\n\n\n\n\n\n\n\n\nTemporality\n\n\n\n\n\n\n\n\n\nWithin subject\n\n\n\n\n\n\n\n\n\\[\\boxed{PPGR_{ij}(t) = \\beta_0(t) + DASH4D_{ij} \\times \\boldsymbol{\\beta_1(t)} + (\\ldots) + U_i(t) + \\epsilon_{ij}(t)}\\]\n\n\n\nPoints to hit:\n\nCGM data are highly correlated time point to time point, see that by tracing the data curves\n\nAgrees with our understanding of the physiology\n\nThis correlation in the response should transfer to the associations between it and a fixed predictor (we see this in our point-wise estimates, actually)\nAnother source of correlation is clustering of curves within subject\n\nPostprandial glucose dynamics might depend upon the subject (particularly their diabetes status, etc)\n\nTo account for both sources, we introduce a functional mixed effects model (detail it)\n\nInterpretations of the coefficient functions are consistent with non-functional models: \\(\\beta_p(t)\\): association with PPGR at time \\(t\\)\n\n\nTransition: As there are numerous methods for estimating temporal fixed effects (splines over time, etc.), we will set the fixed effects aside for now and turn to the random effect U_i(t)."
  },
  {
    "objectID": "talks/Job_Talk.html#modeling-u_it",
    "href": "talks/Job_Talk.html#modeling-u_it",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Modeling \\(U_i(t)\\)",
    "text": "Modeling \\(U_i(t)\\)\n\n\nLongitudinal LME Approach\n\n\n\n\\(U_i(t) = b_{i0} + b_{i1} \\times t + \\ldots\\)\n\n\n\n\n\\(\\{1, t, \\ldots \\}\\): chosen functions\n\\(\\{b_{i0}, b_{i1}, \\ldots \\}\\): correlated RE\n\n\\((b_{i0}, b_{i1}, \\ldots)^t \\sim MVN(\\mathbf{0}, \\Sigma)\\)\n\n\n\n\n\n\nFunctional PCA\n\n\n\n\\(U_i(t) = \\sum_{k = 1}^K \\xi_{ik} \\phi_k(t)\\)\n\n\n\n\n\\(\\phi_k(t)\\): data-driven functional PCs\n\\(\\xi_{ik}\\): scores\n\n\\(\\xi_{ik} \\sim N(0, \\lambda_k)\\) independent\n\n\n\n\n\n\nPoints to hit:\n\nStandard approach: choose bases and let coefficients be flexible multivariate gaussian\n\nMight not represent the data well\nCould become computationally challenging as the number of bases increases\n\nInstead, we use functional principal components analysis (functional PCA)\n\nLet the data decide the basis, FPCs are orthonormal modes of variability that capture the most variability in the data\nFPCs &lt;-&gt; eigenvectors with smoothing/continuity assumption (including the ordering)\n\n\nTransition: Using this representation of the subject-specific random functions, we can return to the functional model for postprandial glucose"
  },
  {
    "objectID": "talks/Job_Talk.html#a-functional-model-for-ppgr",
    "href": "talks/Job_Talk.html#a-functional-model-for-ppgr",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "A Functional Model for PPGR",
    "text": "A Functional Model for PPGR\n\n\\[PPGR_{ij}(t) = \\beta_0(t) + DASH4D_{ij} \\times \\beta_1(t) + (\\ldots) + \\sum_{k = 1}^K \\xi_{ik} \\phi_k(t) + \\epsilon_{ij}(t)\\]\n\n\nStandard approach1:\n\nEstimate \\(\\beta_p(t)\\)\nEstimate \\(\\widehat{\\phi}_k(t)\\) from residuals\nCondition on splines, \\(\\widehat{\\phi}_k(t)\\)\nFit linear mixed effects model\n\n\n\nWhat about uncertainty in \\(\\widehat{\\phi}_k(t)\\)?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAccount for \\(\\widehat{\\phi}_k(t)\\) uncertainty?\nChanged \\(\\beta_p(t)\\) inference?\n\n\n\n\nSubject-level inference?\n\n\n\n\nPoints to hit:\n\nSame functional model with \\(U_i(t)\\) replaced by the FPCA decomposition\nGo through standard procedure\n\nRecall can get good FE estimates (just not inference) in the presence of correlation\nFix spline basis for FE, FPC basis for RE, becomes a simple mixed effects model in the coefficients\n\nWhat if there is uncertainty in the FPC estimates?\n\nShow for our data using resampling, see some rather large deviations\n\nBrings us to our methodological questions\n\nWill cover 1 and 2 immediately, promise to get to 3 shortly.\n\n\nTransition: None\n\n\n\n(Crainiceanu et al., 2024; Scheipl et al., 2015)"
  },
  {
    "objectID": "talks/Job_Talk.html#modeling-phi_kt-as-parameters",
    "href": "talks/Job_Talk.html#modeling-phi_kt-as-parameters",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Modeling \\(\\phi_k(t)\\) as Parameters",
    "text": "Modeling \\(\\phi_k(t)\\) as Parameters\n\nChallenges modeling FPCs:\n\n\nConstrained to be orthogonal (Stiefel manifold)\nMaintain smoothness\n\n\n\n\nLiterature:\n\n\n“A Geometric Approach to Maximum Likelihood Estimation of the Functional Principal Components From Sparse Longitudinal Data” (Peng & Paul, 2009)\n“Generalized Multilevel Function-on-Scalar Regression and Principal Component Analysis” (Goldsmith et al., 2015)\n“Monte Carlo Simulation on the Stiefel Manifold via Polar Expansion” (Jauch et al., 2021)\n“Functional principal component models for sparse and irregularly spaced data by Bayesian inference” (Ye, 2023)\n“Bayesian Functional Principal Components Analysis via Variational Message Passing with Multilevel Extensions” (Nolan et al., 2023)\n\n\n\n\nPoints to hit:\n\nFPCs exist on non-euclidean Stiefel manifold (space of all orthogonal matrices of particular dimension)\nFurther, they occupy a sub-space of this manifold over which certain continuity/smoothness criteria are met\nLots of approaches, from numerical methods on the manifold to fully Bayesian and variational modeling approaches, but there still is not a flexible, computationally efficient, fully-Bayesian approach to this modeling problem.\n\nTransition: This is the gap we seek to address with our MCMC Approach. Many have reservations about the computational efficiency of MCMC, but I assure you we have taken many steps to assure efficiency. With that said, lets get into the details"
  },
  {
    "objectID": "talks/Job_Talk.html#the-fast-approach",
    "href": "talks/Job_Talk.html#the-fast-approach",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "The FAST Approach1",
    "text": "The FAST Approach1\n\n\n\\(\\phi_k(t) = \\mathbf{B}(t)\\psi_k\\) for orthonormal splines \\(\\mathbf{B}(t) = \\{B_1(t), \\ldots , B_Q(t)\\}\\)\n\n\n\n\n\\(\\phi_k(t)\\) are orthonormal \\(\\iff\\) vectors \\(\\psi_k\\) are orthonormal\n\n\n\n\nSubstantial dimension reduction\n\nFPC Functions: \\(\\text{dim}(\\phi_k(t)) = \\infty\\)\nFPC Vectors: \\(\\text{dim}(\\phi_k(t)) &gt;&gt; 100\\)\nFPC Spline Coefficients: \\(\\text{dim}(\\psi_k) \\in [20, 50]\\)\n\n\n\n\n\nChoice of basis \\(\\mathbf{B}(t)\\) is crucial\n\nRestrict to well-behaved \\(\\phi_k(t)\\)\nShapes the \\(\\psi_k\\) space\n\n\n\n\n\nPoints to hit:\n\nMost important point: expand FPCs using an orthonormal basis (FPCs are orthonormal iff the spline coefficients are - have not solved the problem of sampling under orthonormality)\nBasis projection inherently relies upon the functional structure of the data - smooth functions in time are often well-represented by a small number of splines (literature says 20-50 in many applications). Because of this, we achieve substantial dimension reduction\nTwo ways to look at \\(\\phi_k(t)\\), as a function (where we are unable to do any types of calculation) and as a large vector (where computation becomes prohibitively expensive). We instead deal with a moderately sized set of parameters.\nChoice of the basis further restricts the types of functions we are interested in, and shapes the space inhabited by the coefficients. We find a flexible, localized basis of orthonormal splines to be best.\n\nTransition: None\n\n\n\n(Sartini, Zhou, et al., 2025)"
  },
  {
    "objectID": "talks/Job_Talk.html#the-fast-approach-cont.",
    "href": "talks/Job_Talk.html#the-fast-approach-cont.",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "The FAST Approach Cont.",
    "text": "The FAST Approach Cont.\n\n\n\n\n\nPenalized spline priors1 controlling “wiggliness”\n\nAdd \\(-h_k \\int [\\phi_k''(t)]^2 dt\\) to log-likelihood\nUnique smoothing parameters \\(h_k\\)\n\n\n\n\n\n\nModel \\(\\Psi = [\\psi_1 | \\ldots | \\psi_K]\\) using parameter expansion2\n\nSample unconstrained \\(\\mathbf{X}, X_{i,j} \\sim N(0, 1)\\)\nTake SVD \\(\\mathbf{X} = \\mathbf{U}\\boldsymbol{\\Sigma} \\mathbf{V}^t\\)\n\\(\\mathbf{UV}^t\\) is uniform on Stiefel manifold3\n\n\n\n\n\nX = matrix(rnorm(100), \n           ncol = 10, nrow = 10)\nSVD = svd(X)\nPsi = SVD$u %*% t(SVD$v)\n\n\n\n\nPoints to hit:\n\nIntroduce smoothing prior (describe).\n\nSeparate smoothing parameters (and stochastic) important here.\nJust talked about dimension reduction, but we want to restrain the space even further to stabilize the MCMC sampler - so we introduce a smoothing prior\n\nWith the third point, we finally address sampling spline coefficients under orthonormality constraints.\n\nUse very standard parameter expansion approach - easier to model an unconstrained parameter and transform to the constrained space\nOur approach follows that of Jauche and Dunson, leveraging some older statistical results on the Stiefel manifold (Chikuse).\nDiscuss the ease of computation due to simplicity of SVD, small size of coefficient matrix\n\nSampling the latent X, transforming, then applying the posterior smoothing penalty allows us to respect orthonormality constraints while enforcing smoothing of the FPCs\n\nTransition: Combining orthonormality and smoothing did not provide a known distirbutional form, so we had to make sure that this prior was proper for our model to be well-formulated.\n\n(Craven & Wahba, 1979)(Jauch et al., 2021)(Chikuse, 2003)"
  },
  {
    "objectID": "talks/Job_Talk.html#fast-fpc-prior",
    "href": "talks/Job_Talk.html#fast-fpc-prior",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "FAST FPC Prior",
    "text": "FAST FPC Prior\n\n\\(\\int [\\phi_k''(t)]^2 dt \\approx \\psi_k^t \\mathbf{P} \\psi_k\\) for penalty matrix \\(\\mathbf{P}\\) defined by \\(\\mathbf{B}(t)\\)\n\n\n\n\\[f(\\psi_k|h_k) \\propto \\text{MVN}\\left(\\mathbf{0}, (h_k\\mathbf{P})^{-1}\\right) \\times \\mathbf{I}(\\psi_k \\text{ are orthonormal})\\]\n\n\\(h_k\\) smoothing parameters have Gamma\\((\\alpha, \\beta)\\) priors\nSmoothing spline prior1 with additional orthonormality constraint\n\nProposition: The joint prior distribution on \\(\\psi_k, h_k\\) is proper if and only if \\(2\\beta\\) is greater than the first eigenvalue of the penalty matrix \\(\\mathbf{P}\\)\n\n\nPoints to hit:\n\nIntegral quantifying “wiggliness” can be approximated as a quadratic form in the spline coefficients with penalty matrix P which follows directly from the basis choice B\nSpline coefficient prior given the corresponding smoothing parameter is proportional to MVN, but it is not a proper MVN due to the precision being singular\nSmoothing parameters have independent gamma priors with chosen shapes alpha and rates beta\nThis is equivalent to a smoothing spline prior with the additional constraint of orthonormality\nWe can ensure that this condition holds in our model design. Set hyper-parameter beta based on the fixed penalty matrix (given the chosen basis).\n\nTransition: None\n\n\n\n(Craven & Wahba, 1979)"
  },
  {
    "objectID": "talks/Job_Talk.html#agenda-2",
    "href": "talks/Job_Talk.html#agenda-2",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Agenda",
    "text": "Agenda\n\n\nModeling Continuous Glucose Monitor (CGM) Data\nA Bayesian Functional Model for CGM Data\nModel Performance\nModel Inference on CGM\nExtending our approach\n\n\n\nTransition: Ok, but how well does this combination of ideas work?"
  },
  {
    "objectID": "talks/Job_Talk.html#simulation-validation",
    "href": "talks/Job_Talk.html#simulation-validation",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Simulation Validation",
    "text": "Simulation Validation\n\n\nReal data and canonical examples\nSimilar/improved accuracy of point estimates\nNominal coverage of credible intervals\n\n\n\nPoints to hit:\n\nSimulation scenarios mimicking real data and canonical examples\nSimilar/improved accuracy compared to fully-Bayesian and variational alternatives\n\nAccuracy improvement is more noticeable in the later FPCs\n\nNominal coverage of posterior credible intervals\nCloser look in the appendix\n\nTransition: Seems to do well, but what about the computational efficiency?"
  },
  {
    "objectID": "talks/Job_Talk.html#computation",
    "href": "talks/Job_Talk.html#computation",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Computation",
    "text": "Computation\n\n\n\\(50-90\\%\\) reduction relative to alternatives\n\n\n\n\nOur application: \\(768\\) functions with \\(20\\) obs: \\(\\approx 15\\) minutes\n\n\n\n\nSimulations\n\n\\(50\\) functions with \\(500\\) obs: \\(\\approx 35\\) minutes\n\\(500\\) functions with \\(50\\) obs: \\(\\approx 15\\) minutes\n\nScales linearly in functions and obs.\n\n\n\n\n\nEfficiency improvements underway \\(\\rightarrow\\)\n\n\n\n\n\n\n\nPoints to hit:\n\nMuch faster than fully-Bayesian alternatives\nComputations for moderate-scale problems are on the scale of minutes\nComplexity currently scales linearly in terms of number of functions and number of observations per function\nActively working to improve this\n\nExperimental version does not scale with number of observations at all, making the approach feasible for modern, very dense data\n\n\nTransition: None"
  },
  {
    "objectID": "talks/Job_Talk.html#agenda-3",
    "href": "talks/Job_Talk.html#agenda-3",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Agenda",
    "text": "Agenda\n\n\nModeling Continuous Glucose Monitor (CGM) Data\nA Bayesian Functional Model for CGM Data\nModel Performance\nModel Inference on CGM\nExtending our approach\n\n\n\nTransition: With that said, now we return to the problem that actually motivated all of this work, how does the DASH4D diet impact postprandial glucose response"
  },
  {
    "objectID": "talks/Job_Talk.html#dash4d-diet-effect",
    "href": "talks/Job_Talk.html#dash4d-diet-effect",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "DASH4D Diet Effect",
    "text": "DASH4D Diet Effect\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoints to hit:\n\nSee quite similar point estimates (as we would expect based upon multilevel modeling results)\nSubstantively: max drop of ~ 16 mg/dL between 1 and 2 hours, ~5 mg/dL fasting difference\nDo see some small differences in widths of the uncertainty bounds\n\nParticularly in the fasting period where point-wise models indicate significance at this alpha level and FAST does not\n\n\nTransition: But we can learn even more from this data by virtue of choosing a Bayesian framework. We have posterior distributions for all model parameters of interest."
  },
  {
    "objectID": "talks/Job_Talk.html#variability-decomposition",
    "href": "talks/Job_Talk.html#variability-decomposition",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Variability Decomposition",
    "text": "Variability Decomposition\n\n\\[PPGR_{ij}(t) = \\color{#619CFF}{\\beta_0(t) + DASH4D_{ij} \\times \\beta_1(t) + (\\ldots)} + \\color{#00BA38}{\\sum_{k = 1}^K \\xi_{ik} \\phi_k(t)} + \\color{#F8766D}{\\epsilon_{ij}(t)}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoints to hit:\n\nThe fixed effects we were so interested in explain relatively little variability in the data\n\nWe would be missing quite a bit if we performed prediction using just these elements\n\nMost variability explained at the subject level\n\nTransition: We can further understand what this variability looks like, a feature of using FPCA"
  },
  {
    "objectID": "talks/Job_Talk.html#variability-decomposition-1",
    "href": "talks/Job_Talk.html#variability-decomposition-1",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Variability Decomposition",
    "text": "Variability Decomposition\n\n\\[PPGR_{ij}(t) = \\beta_0(t) + DASH4D_{ij} \\times \\beta_1(t) + (\\ldots) + \\sum_{k = 1}^K \\xi_{ik} \\phi_k(t) + \\epsilon_{ij}(t)\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoints to hit:\n\nAlmost all of the variability (according to eigenvalue) at the subject level is explained by the first FPC\nFirst FPC looks a bit like a sterotypical CGM response (explain)\n\nTransition: So, what does this mean?"
  },
  {
    "objectID": "talks/Job_Talk.html#variability-decomposition-2",
    "href": "talks/Job_Talk.html#variability-decomposition-2",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Variability Decomposition",
    "text": "Variability Decomposition\n\n\\[PPGR_{ij}(t) = \\beta_0(t) + DASH4D_{ij} \\times \\beta_1(t) + (\\ldots) + \\sum_{k = 1}^K \\xi_{ik} \\phi_k(t) + \\epsilon_{ij}(t)\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoints to hit:\n\nParticipants with higher scores on the first FPC (\\(\\xi_{i1}\\)) will have trajectories which start higher and have more exaggerated response\n\nSee for example the red points, chosen from a subject with high value for \\(\\xi_{i1}\\)\n\nIn the reverse, those with lower scores \\(\\xi_{i1}\\) will have lower starts and more mild response\n\nSee for example the blue points\n\n\nTransition: These insights were only possible because of the combination of a functional modeling perspective with a Bayesian framework."
  },
  {
    "objectID": "talks/Job_Talk.html#why-fast-for-functional-modeling",
    "href": "talks/Job_Talk.html#why-fast-for-functional-modeling",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Why FAST for Functional Modeling?",
    "text": "Why FAST for Functional Modeling?\n\n\nFully-Bayesian: estimates \\(+\\) uncertainty for any quantity of interest\nAccounts for all known sources of correlation and uncertainty\n\nValid inferences\n\n\n\n\n\nComputationally efficient and stable\nImplemented in standard software (STAN)\n\n\n\n\nWe have developed an accessible R package\n\nAvailable at https://github.com/JSartini/BFun\n\n\n\ndash_fit = bfmm(Glucose ~ DASH4D + Age + BMI + Gender + TOD, id = ID)\n\n\n\nPoints to hit:\n\nFully Bayesian - we get quite a lot for free with each run, and all known sources of correlation and uncertainty are accounted for (produces valid inference)\nEfficient due to our choice of a restrictive prior/dimensionality reduction\nEasily accessible - can implement or extend if you are aware of STAN\nFor those less familiar with STAN, can just use the R package we very recently made available on GitHub\n\nStill under active development (adding features and fixing bugs)\nProvides all necessary tools, including convergence monitoring\n\n\nTransition: Handy tool here, but can it do more? No assumptions were made which limit us from being able to apply it to a broad range of additional contexts"
  },
  {
    "objectID": "talks/Job_Talk.html#generalization",
    "href": "talks/Job_Talk.html#generalization",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Generalization",
    "text": "Generalization\n\n\n\n\n\n\n\nPoints to hit:\n\nI realized that there were many potential new contexts to which FAST could be adapted (detail them)\nAround the time that I realized this, I started working with some irregularly-measured longitudinal growth data, leading to a particular extension being the first I explored\n\nTransition: None"
  },
  {
    "objectID": "talks/Job_Talk.html#agenda-4",
    "href": "talks/Job_Talk.html#agenda-4",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Agenda",
    "text": "Agenda\n\n\nModeling Continuous Glucose Monitor (CGM) Data\nA Bayesian Functional Model for CGM Data\nModel Performance\nModel Inference on CGM\nExtension to Multivariate, Sparse Data\n\n\n\nTransition: Leads us into the final point, extending the model to a new scenario, specifically focusing on multivariate, sparse data collected as part of a child growth study."
  },
  {
    "objectID": "talks/Job_Talk.html#the-content-study",
    "href": "talks/Job_Talk.html#the-content-study",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "The CONTENT Study1",
    "text": "The CONTENT Study1\n\n\nHelicopactor pylori \\(\\Rightarrow\\) child growth\nMay 2007 - Feb 2011 near Lima City, Peru\nLongitudinal cohort of \\(N = 197\\) selected randomly from census\n\n\n\n\nLength and weight measures2\n\nZ-scored to age/gender WHO standards\nIncreasing sparsity of observation over time\nMissing/cancelled visits\n\n\n\n\nPoints to hit:\n\nBasic information about the study (read slide here)\nZ scores means that values can decrease (not an absolute negative change in length or weight)\nNote that this data is packaged with the refund package in R.\n\n\n(Checkley et al., 1998; Checkley et al., 2003)(Crainiceanu et al., 2024)"
  },
  {
    "objectID": "talks/Job_Talk.html#content-data",
    "href": "talks/Job_Talk.html#content-data",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "CONTENT Data",
    "text": "CONTENT Data\n\n\n\n\n\n\n\n\n\n\n\n\nCan we (dynamically) infer growth trajectories?\n\n\nPoints to hit:\n\nData’s increasing sparsity\nDifferential observation across participants\nCorrelation between measures\nCan we predict trajectories for individuals with less data using information we learned from the others (leveraging the correlation between these two meaasures)?\n\nTransition: What do we mean by dynamic prediction"
  },
  {
    "objectID": "talks/Job_Talk.html#content-prediction",
    "href": "talks/Job_Talk.html#content-prediction",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "CONTENT Prediction",
    "text": "CONTENT Prediction\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoints to hit:\n\nFollow the points, shows what we would see as we collect the data\nFor this scenario and many similar ones, it is useful to predict where the measures are going given our understanding of their covariance and what we have seen for other participants\n\nIdentify problematic trajectories early\n\n\nTransition: Where does FAST come in for this problem? Well, we can use multivariate functional modeling to learn the covariance structure from our sparsely observed data."
  },
  {
    "objectID": "talks/Job_Talk.html#multivariate-functional-pca",
    "href": "talks/Job_Talk.html#multivariate-functional-pca",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Multivariate Functional PCA1",
    "text": "Multivariate Functional PCA1\n\\[\\begin{pmatrix}W_{i}(t)\\\\ L_i(t) \\end{pmatrix}\n   = \\begin{pmatrix}\\mu^{(W)}(t; X_{i})\\\\ \\mu^{(L)}(t; X_{i}) \\end{pmatrix} + \\sum_{k = 1}^K \\xi_{ik} \\begin{pmatrix}\\phi^{(W)}_{k}(t)\\\\ \\phi^{(L)}_k(t) \\end{pmatrix} + \\begin{pmatrix}\\epsilon^{(W)}_i(t) \\\\ \\epsilon^{(L)}_i(t) \\end{pmatrix}\\]\n\n\n\\(\\mu^{(W)}(t; X_i), \\mu^{(L)}(t; X_i)\\): variate-specific means\n\\(\\xi_{ik} \\sim N(0, \\lambda_k)\\): independent scores\n\\(\\Phi_k(t) = \\begin{pmatrix} \\phi^{(W)}_k(t) \\\\ \\phi^{(L)}_k(t) \\end{pmatrix}\\): joint, data-driven FPCs\n\\(\\epsilon^{(W)}_i(t), \\epsilon^{(L)}_i(t)\\): independent, normal errors\n\n\n\n\n\n\nPoints to hit:\n\nDescribe the equation, identical to univariate same statistics apply to concatenated functions\nPoint out the shared scores across variates, where the cross-covariances are held\nSquint and it looks an awful lot like the univariate FPCA, very similar computationally if we stack and just smooth over individual domains\nShow what I mean by concatenation\n\nTransition: So, FAST is applicable, but what changes to we need to make?\n\n(Happ & Greven, 2018)"
  },
  {
    "objectID": "talks/Job_Talk.html#multivariate-sparse-fast-msfast",
    "href": "talks/Job_Talk.html#multivariate-sparse-fast-msfast",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Multivariate, Sparse FAST (MSFAST)",
    "text": "Multivariate, Sparse FAST (MSFAST)\n\nAdjustments:\n\nSparsity handled by splines\nConcatenate the FPCs\nScale variates in pre-processing\nMore robust posterior FPC alignment\n\n\n\nSimulations:\n\n2-4 variables\nCompared to available software1\n\n\\(25\\)-\\(50\\%\\) error reduction\nAccurate estimates\nCompetitive computation\n\nNominal coverage\n\n\n\n\nPoints to hit:\n\nEach of the updates\nSimulations validated\n\nHit each of the given points\nMSFAST is particularly better than alternatives for later eigenfunctions with smaller signals.\n\n\n\n\n\n(Happ & Greven, 2018; Li et al., 2020; Nolan et al., 2025)"
  },
  {
    "objectID": "talks/Job_Talk.html#trajectory-prediction",
    "href": "talks/Job_Talk.html#trajectory-prediction",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Trajectory Prediction",
    "text": "Trajectory Prediction\n\n\nLearn \\(\\phi_k^{(p)}(t)\\), \\(\\mu^{(p)}(t; X_i)\\)\nNew scores \\(\\xi_{ik}\\) are conditionally Gaussian\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoints to hit:\n\nHow we do this: fit the model on the observed data, draw posterior of population parameters\nConditional distribution of new subject scores given the population parameters and the associated data is Gaussian, simple to draw from\nFollow the female in the left: diverging is mitigated"
  },
  {
    "objectID": "talks/Job_Talk.html#ongoing-work",
    "href": "talks/Job_Talk.html#ongoing-work",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Ongoing Work",
    "text": "Ongoing Work\n\n\n\n\n1(Sartini, Zhou, et al., 2025)\n2(Sartini, Zeger, et al., 2025)\n\n\nPoints to hit:\n\nWhat we have already covered\nDense data (touched on briefly before) makes FAST feasible for much higher-dimensional data\nGeneralized: CGM and ECG co-evolution (indicators for arrhythmia)\n\nGeneral idea: follows the same principle as generalized linear models, greater detail/visualization if wanted\n\nNothing stopping us from doing repeat measures\n\nTransition: None"
  },
  {
    "objectID": "talks/Job_Talk.html#Review",
    "href": "talks/Job_Talk.html#Review",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "",
    "text": "FAST: https://github.com/JSartini/FAST-BFPCA\nMSFAST: https://github.com/JSartini/MSFAST_B-m-FPCA\nPackage: https://github.com/JSartini/BFun\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJust a bit summary for this talk, as well as my research philosophy as a whole\nPoints to hit:\n\nStart with a scientific problem I am interested in (can talk about Cooper)\nEngaged collaboration with subject matter experts, name everyone\nBased on what I learn from the data and my own statistical background, worked with Dr. Zeger and Crainiceanu to form a particular representation of the data and corresponding algorithm\nActually implement it and make it available\nCan take it to new problems, for example the growth trajectory problem or new wearables (e-patch)\n\nThank you, I would be happy to answer any questions"
  },
  {
    "objectID": "talks/Job_Talk.html#references",
    "href": "talks/Job_Talk.html#references",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "References",
    "text": "References\n\n\nAmerican Diabetes Association Professional Practice Committee for Diabetes*. (2025). 1. Improving Care and Promoting Health in Populations: Standards of Care in Diabetes—2026. Diabetes Care, 49(Supplement_1), S13–S26. https://doi.org/10.2337/dc26-S001\n\n\nBaumblatt, J., Fryar, C., Gu, Q., & Ashman, J. (2024). Prevalence of Total, Diagnosed, and Undiagnosed Diabetes in Adults: United States, August 2021–August 2023. National Center for Health Statistics (U.S.). https://doi.org/10.15620/cdc/165794\n\n\nCheckley, W., Epstein, L. D., Gilman, R. H., Black, R. E., Cabrera, L., & Sterling, C. R. (1998). Effects of Cryptosporidium parvum infection in Peruvian children: Growth faltering and subsequent catch-up growth. American Journal of Epidemiology, 148(5), 497–506. https://doi.org/10.1093/oxfordjournals.aje.a009675\n\n\nCheckley, W., Epstein, L. D., Gilman, R. H., Cabrera, L., & Black, R. E. (2003). Effects of acute diarrhea on linear growth in Peruvian children. American Journal of Epidemiology, 157(2), 166–175. https://doi.org/10.1093/aje/kwf179\n\n\nChikuse, Y. (2003). Statistics on Special Manifolds (P. Bickel, P. Diggle, S. Fienberg, K. Krickeberg, I. Olkin, N. Wermuth, & S. Zeger, Eds.; Vol. 174). Springer. https://doi.org/10.1007/978-0-387-21540-2\n\n\nCrainiceanu, C. M., Goldsmith, J., Leroux, A., & Cui, E. (2024). Functional Data Analysis with R. Chapman; Hall/CRC. https://doi.org/10.1201/9781003278726\n\n\nCraven, P., & Wahba, G. (1979). Smoothing noisy data with spline functions. Numerische Mathematik, 1, 377–403.\n\n\nCui, E., Leroux, A., Smirnova, E., & Crainiceanu, C. M. (2022). Fast Univariate Inference for Longitudinal Functional Models. Journal of Computational and Graphical Statistics : A Joint Publication of American Statistical Association, Institute of Mathematical Statistics, Interface Foundation of North America, 31(1), 219–230. https://doi.org/10.1080/10618600.2021.1950006\n\n\nFang, M., Wang, D., Rebholz, C. M., Echouffo-Tcheugui, J. B., Tang, O., Wang, N.-Y., Mitchell, C. M., Pilla, S. J., Appel, L. J., & Selvin, E. (2025). DASH4D diet for glycemic control and glucose variability in type 2 diabetes: A randomized crossover trial. Nature Medicine, 1–8. https://doi.org/10.1038/s41591-025-03823-3\n\n\nGoldsmith, J., Zipunnikov, V., & Schrack, J. (2015). Generalized Multilevel Function-on-Scalar Regression and Principal Component Analysis. Biometrics, 71(2), 344–353. https://doi.org/10.1111/biom.12278\n\n\nHapp, C., & Greven, S. (2018). Multivariate Functional Principal Component Analysis for Data Observed on Different (Dimensional) Domains. Journal of the American Statistical Association, 113(522), 649–659. https://doi.org/10.1080/01621459.2016.1273115\n\n\nJauch, M., Hoff, P. D., & Dunson, D. B. (2021). Monte Carlo Simulation on the Stiefel Manifold via Polar Expansion. Journal of Computational and Graphical Statistics, 30(3), 622–631. https://doi.org/10.1080/10618600.2020.1859382\n\n\nLi, C., Xiao, L., & Luo, S. (2020). Fast covariance estimation for multivariate sparse functional data. Stat (International Statistical Institute), 9(1), e245. https://doi.org/10.1002/sta4.245\n\n\nNolan, T. H., Goldsmith, J., & Ruppert, D. (2023). Bayesian Functional Principal Components Analysis via Variational Message Passing with Multilevel Extensions. Bayesian Analysis, -1(-1), 1–27. https://doi.org/10.1214/23-BA1393\n\n\nNolan, T. H., Richardson, S., & Ruffieux, H. (2025). Efficient Bayesian functional principal component analysis of irregularly-observed multivariate curves. Computational Statistics & Data Analysis, 203, 108094. https://doi.org/10.1016/j.csda.2024.108094\n\n\nParker, E. D., Lin, J., Mahoney, T., Ume, N., Yang, G., Gabbay, R. A., ElSayed, N. A., & Bannuru, R. R. (2024). Economic Costs of Diabetes in the U.S. In 2022. Diabetes Care, 47(1), 26–43. https://doi.org/10.2337/dci23-0085\n\n\nPeng, J., & Paul, D. (2009). A Geometric Approach to Maximum Likelihood Estimation of the Functional Principal Components From Sparse Longitudinal Data. Journal of Computational and Graphical Statistics, 18(4), 995–1015. https://doi.org/10.1198/jcgs.2009.08011\n\n\nPilla, S. J., Yeh, H.-C., et al. (2025). Dietary Patterns, Sodium Reduction, and Blood Pressure in Type 2 Diabetes: The DASH4D Randomized Clinical Trial. JAMA Internal Medicine. https://doi.org/10.1001/jamainternmed.2025.1580\n\n\nSartini, J., Zeger, S., & Crainiceanu, C. (2025). Bayesian Multivariate Sparse Functional PCA. arXiv. https://doi.org/10.48550/arXiv.2509.03512\n\n\nSartini, J., Zhou, X., Selvin, L., Zeger, S., & Crainiceanu, C. M. (2025). Fast bayesian functional principal components analysis. Journal of Computational and Graphical Statistics, 0(ja), 1–20. https://doi.org/10.1080/10618600.2025.2592768\n\n\nScheipl, F., Staicu, A.-M., & Greven, S. (2015). Functional Additive Mixed Models. Journal of Computational and Graphical Statistics : A Joint Publication of American Statistical Association, Institute of Mathematical Statistics, Interface Foundation of North America, 24(2), 477–501. https://doi.org/10.1080/10618600.2014.901914\n\n\nYe, J. (2023). Functional principal component models for sparse and irregularly spaced data by Bayesian inference. Journal of Applied Statistics, 1(31). https://doi.org/https://doi.org/10.1080/02664763.2023.2197587"
  },
  {
    "objectID": "talks/Job_Talk.html#dash4d-design",
    "href": "talks/Job_Talk.html#dash4d-design",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "DASH4D Design",
    "text": "DASH4D Design"
  },
  {
    "objectID": "talks/Job_Talk.html#fast-accuracy",
    "href": "talks/Job_Talk.html#fast-accuracy",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "FAST Accuracy",
    "text": "FAST Accuracy"
  },
  {
    "objectID": "talks/Job_Talk.html#fast-coverage",
    "href": "talks/Job_Talk.html#fast-coverage",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "FAST Coverage",
    "text": "FAST Coverage"
  },
  {
    "objectID": "talks/Job_Talk.html#fast-univariate-inference",
    "href": "talks/Job_Talk.html#fast-univariate-inference",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Fast Univariate Inference1",
    "text": "Fast Univariate Inference1\n\n\nFit local linear mixed effects models\nSmooth along the functional domain\nPoint-wise confidence bands using the smoothing operator\nJoint confidence bands using analytic procedure or bootstrap\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFUI is an alternative method (from our group) which can fit types of models. FUI is focused on just fixed effects estimation, so it does not model the random effects explicitly.\nBe sure to say:\n\nVery computationally efficient (parallelizable)\nDoes not model the random effects \\(U_i(t)\\), marginalizes them out\n\n\n\n\n\n(Cui et al., 2022)"
  },
  {
    "objectID": "talks/Job_Talk.html#fast-vs-fui",
    "href": "talks/Job_Talk.html#fast-vs-fui",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "FAST vs FUI",
    "text": "FAST vs FUI\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMoving the needle for fasting glucose?\n\n\n\nVery similar fixed effects, but a bit different on the inference (only small, but deserves further interpretation)"
  },
  {
    "objectID": "talks/Job_Talk.html#fast-timing---n",
    "href": "talks/Job_Talk.html#fast-timing---n",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "FAST Timing - N",
    "text": "FAST Timing - N"
  },
  {
    "objectID": "talks/Job_Talk.html#fast-timing---m",
    "href": "talks/Job_Talk.html#fast-timing---m",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "FAST Timing - M",
    "text": "FAST Timing - M"
  },
  {
    "objectID": "talks/Job_Talk.html#faster-description",
    "href": "talks/Job_Talk.html#faster-description",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "FASTer Description",
    "text": "FASTer Description\n\n\nProject \\(Y_i(t) = \\mathbf{B}(t) \\eta_i\\), only model \\(\\eta_i\\)\nChoose \\(\\mathbf{B}(t)\\) to be vector orthonormal (matrix \\(\\mathbf{B}\\))\n\n\\(\\eta_i = (\\mathbf{B}^T \\mathbf{B})^{-1}\\mathbf{B}^t Y_i = \\mathbf{B}^t Y_i\\), still independent\n\nComputations should not scale with observations per function\n\n\n\nPreliminary Results:\n\n\n\n\n\n\n\n\n\n\n\nFrom preliminary results - estimates and coverage match FAST. Computation times in box plot"
  },
  {
    "objectID": "talks/Job_Talk.html#faster-accuracy",
    "href": "talks/Job_Talk.html#faster-accuracy",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "FASTer Accuracy",
    "text": "FASTer Accuracy"
  },
  {
    "objectID": "talks/Job_Talk.html#faster-coverage",
    "href": "talks/Job_Talk.html#faster-coverage",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "FASTer Coverage",
    "text": "FASTer Coverage"
  },
  {
    "objectID": "talks/Job_Talk.html#msfast-trajectory-accuracy",
    "href": "talks/Job_Talk.html#msfast-trajectory-accuracy",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "MSFAST Trajectory Accuracy",
    "text": "MSFAST Trajectory Accuracy"
  },
  {
    "objectID": "talks/Job_Talk.html#msfast-trajectory-coverage",
    "href": "talks/Job_Talk.html#msfast-trajectory-coverage",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "MSFAST Trajectory Coverage",
    "text": "MSFAST Trajectory Coverage"
  },
  {
    "objectID": "talks/Job_Talk.html#msfast-fpc-accuracy",
    "href": "talks/Job_Talk.html#msfast-fpc-accuracy",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "MSFAST FPC Accuracy",
    "text": "MSFAST FPC Accuracy"
  },
  {
    "objectID": "talks/Job_Talk.html#msfast-fpc-coverage",
    "href": "talks/Job_Talk.html#msfast-fpc-coverage",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "MSFAST FPC Coverage",
    "text": "MSFAST FPC Coverage"
  },
  {
    "objectID": "talks/Job_Talk.html#generalized-functional-pca",
    "href": "talks/Job_Talk.html#generalized-functional-pca",
    "title": "Fully-Bayesian Functional Modeling of Continuous Glucose Monitoring Data",
    "section": "Generalized Functional PCA",
    "text": "Generalized Functional PCA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[g\\bigl(\\mathbb{E}[Y_i(t)]\\bigr) = \\mu(t; X_{i}) + \\sum_{k = 1}^K \\xi_{ik}\\phi_k(t)\\]"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Johns Hopkins University - Bloomberg SPH | August 2021 - present\n\n\n\nPrinceton University | August 2017 - May 2021"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Me",
    "section": "",
    "text": "Johns Hopkins University - Bloomberg SPH | August 2021 - present\n\n\n\nPrinceton University | August 2017 - May 2021"
  },
  {
    "objectID": "about.html#research-groups",
    "href": "about.html#research-groups",
    "title": "About Me",
    "section": "Research Groups",
    "text": "Research Groups\n\nJohns Hopkins University\n\nWearable and Implantable Technology (WIT) Working Group | December 2022 - present\nDiabetes Data Group | August 2022 - present\nZeger Lab | August 2022 - present\n\n\n\n\nPresentation of Applied Research at AHA Epi/Lifestyle 2025\n\n\n\n\nPrinceton University\n\nIndirect Reciprocity Working Group | November 2019 - August 2021\nTransportation Systems Lab | May 2020 - September 2020\n\n\n\nUniversity of Arkansas\n\nSystems Engineering Lab | May 2020 - May 2021"
  },
  {
    "objectID": "about.html#teaching-experience",
    "href": "about.html#teaching-experience",
    "title": "About Me",
    "section": "Teaching Experience",
    "text": "Teaching Experience\n\nJohns Hopkins University\n\nAnalysis of Longitudinal and Multilevel Data Lead TA | Fall 2025\nPrivate Tutoring in Statistical Methods and Theory | May 2023 - present\nStatistical Computing and Machine Learning TA | August 2022 - May 2025\nTA Training Planning Committee | 2023-2025\n\n\n\n\nGuest Lecture to Undergraduate Biostatistics Students Covering my Research\n\n\n\n\nPrinceton Univeristy\n\nStatistical Courses TA | August 2020 - May 2021"
  },
  {
    "objectID": "about.html#honors-and-awards",
    "href": "about.html#honors-and-awards",
    "title": "About Me",
    "section": "Honors and Awards",
    "text": "Honors and Awards\n\nLouis I. and Thomas D. Dublin Award for the Advancement of Epidemiology and Biostatistics | 2025\nHelen Abbey Award for Commitment to Teaching | 2024\nAhmet S. Çakmak Prize for Innovative Research | 2021\nGeorge J. Mueller Award for High Scholarly Achievement and Quality Athletic Performance | 2021"
  },
  {
    "objectID": "about.html#software-experience",
    "href": "about.html#software-experience",
    "title": "About Me",
    "section": "Software Experience",
    "text": "Software Experience\nSoftware Engineering Intern | PrivacyStar | May 2019 - August 2019"
  },
  {
    "objectID": "soft.html",
    "href": "soft.html",
    "title": "Software",
    "section": "",
    "text": "BFun: Bayesian Functional (Mixed) Modeling | The goal of BFun is to provide the tools necessary to fit Bayesian functional (mixed) models where random effects are represented using stochastic eigenfunctions. This type of joint modeling accounts for all potential sources of uncertainty, providing valid inferences even when signal to noise ratio is small. The package is oriented around a Markov Chain Monte Carlo approach, but provides an experimental variational implementation as well (still undergoing testing).\nMSFAST Bayesian Multivariate Sparse FPCA | Supporting material for the manuscript introducing the MSFAST approach to Bayesian Functional Principal Components Analysis for multivariate, sparsely-observed data. Includes STAN and R codes providing univariate and multivariate sparse data simulations comparing MSFAST with existing implementations, evaluating estimation accuracy and inference validity. Additionally includes a vignette illustrating a real analysis on the CONTENT child growth data.\nFAST Bayesian FPCA | Supporting material for the manuscript introducing the FAST approach to fitting Bayesian Functional Principal Components Analysis. Includes STAN and R codes providing simulation and model fitting routines comparing FAST with existing implementations on a simple simulation scenario and a multilevel scenario, evaluating estimation accuracy and inference validity.\nrGCI | Supporting R software for calculation of the novel Glucose Color Index (GCI) frequency-domain summary of Continuous Glucose Monitoring Data. Includes tools for calculating the smoothed log-periodogram using two weeks of glucose data, summarizing this function into 6 measures using a piece-wise linear model, and finally producing the GCI using weights derived via canonical correlation analysis."
  }
]